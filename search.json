[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data, donuts, and detours",
    "section": "",
    "text": "Setting up a wildlife camera\n\n\nIt’s almost like the corporate solutions are on to something\n\n\n\n\npersonal\n\n\nraspberry pi\n\n\nwildlife\n\n\nir\n\n\ncamera\n\n\nvideo processing\n\n\n\n\n\n\n\n\n\n\n\nFebruary 15, 2023\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nMastodon, Part III: Configuring and installing the prerequisites\n\n\nWelcome to dependency hell, we have recursion\n\n\n\n\npersonal\n\n\nraspberry pi\n\n\nk3s\n\n\nmastodon\n\n\ndependencies\n\n\n\n\n\n\n\n\n\n\n\nFebruary 9, 2023\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nMastodon, Part II: The Mastodon Helm chart\n\n\nA package manager for people who enjoy pain I guess\n\n\n\n\npersonal\n\n\nraspberry pi\n\n\nk3s\n\n\nmastodon\n\n\nhelm\n\n\n\n\n\n\n\n\n\n\n\nJanuary 25, 2023\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nMastodon, Part I: My home network topology\n\n\nDNS. It’s always DNS. Except when it’s not.\n\n\n\n\npersonal\n\n\nraspberry pi\n\n\nk3s\n\n\nmastodon\n\n\nnetworking\n\n\n\n\n\n\n\n\n\n\n\nJanuary 23, 2023\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nRunning your own Mastodon instance on a Raspberry Pi k3s cluster\n\n\nNow you too can unwittingly become an unpaid sysadmin!\n\n\n\n\npersonal\n\n\nraspberry pi\n\n\nk3s\n\n\nmastodon\n\n\n\n\n\n\n\n\n\n\n\nJanuary 20, 2023\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\n2022: A year in review\n\n\nLast year doesn’t deserve a rhyming couplet\n\n\n\n\npersonal\n\n\nprofessional\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJanuary 17, 2023\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nPardon de dust (2)\n\n\nMigrating blog backends is hard\n\n\n\n\npersonal\n\n\nprofessional\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nDecember 13, 2022\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nBreath of Fresh (albeit, indoor) Air\n\n\n\n\n\n\n\npersonal\n\n\nbreath of the wild\n\n\nzelda\n\n\nrunning\n\n\ngaming\n\n\nnerds\n\n\nthe lady\n\n\ninjury\n\n\n\n\n\n\n\n\n\n\n\nAugust 12, 2019\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nQuinnwitz in Ireland\n\n\n\n\n\n\n\npersonal\n\n\ntravel\n\n\nireland\n\n\n\n\n\n\n\n\n\n\n\nJune 3, 2019\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nStarCraft II Questions\n\n\n\n\n\n\n\npersonal\n\n\ngaming\n\n\nvideo games\n\n\n\n\n\n\n\n\n\n\n\nJanuary 31, 2019\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nJedi Outcast: Echoes of a bygone gaming era\n\n\n\n\n\n\n\npersonal\n\n\ngaming\n\n\nstar wars\n\n\nfps\n\n\ncommunities\n\n\n\n\n\n\n\n\n\n\n\nApril 26, 2018\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nResolutions for 2018\n\n\n\n\n\n\n\npersonal\n\n\nprofessional\n\n\nnew year\n\n\nblog\n\n\nwriting\n\n\nside projects\n\n\nresearch\n\n\n\n\n\n\n\n\n\n\n\nJanuary 21, 2018\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nNew year, new blog layout\n\n\n\n\n\n\n\npersonal\n\n\nnew year\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nJanuary 6, 2018\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nSummer of Data Science 2017\n\n\n\n\n\n\n\nprofessional\n\n\npersonal\n\n\ndata science\n\n\npython\n\n\ncomputer vision\n\n\nimaging\n\n\nmachine learning\n\n\ndeep learning\n\n\nnvidia\n\n\ngpu\n\n\nteaching\n\n\neducation\n\n\nbioimaging\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2017\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nSo, you want to conduct research with me?\n\n\n\n\n\n\n\nprofessional\n\n\nphd\n\n\ngraduate school\n\n\nresearch\n\n\nmentoring\n\n\ncomputer science\n\n\ngraduate student\n\n\n\n\n\n\n\n\n\n\n\nMarch 16, 2017\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nGame-ify Your Raspberry Pi\n\n\n\n\n\n\n\npersonal\n\n\nraspberry pi\n\n\ngaming\n\n\nvideo games\n\n\nnvidia\n\n\nsteam\n\n\n\n\n\n\n\n\n\n\n\nJanuary 6, 2017\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nOpen Science in Big Data (OSBD) Workshop\n\n\n\n\n\n\n\nprofessional\n\n\nworkshop\n\n\nbig data\n\n\nieee\n\n\nopen science\n\n\n\n\n\n\n\n\n\n\n\nSeptember 26, 2016\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nA twitterbot for posting weekly running stats\n\n\n\n\n\n\n\npersonal\n\n\npython\n\n\nstrava\n\n\nrunning\n\n\noauth\n\n\ntweepy\n\n\ntwitter\n\n\npybot\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2016\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nReviewing a reviewed grant’s reviews\n\n\n\n\n\n\n\nprofessional\n\n\nacademia\n\n\ngrants\n\n\nfeedback\n\n\nrejection\n\n\n\n\n\n\n\n\n\n\n\nFebruary 2, 2016\n\n\nShannon Quinn\n\n\n\n\n\n\n  \n\n\n\n\nIntroductions\n\n\n\n\n\n\n\npersonal\n\n\npelican\n\n\npython\n\n\ngithub\n\n\njupyter\n\n\n\n\n\n\n\n\n\n\n\nNovember 7, 2015\n\n\nShannon Quinn\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2016-09-26-osbd2016-workshop/index.html",
    "href": "posts/2016-09-26-osbd2016-workshop/index.html",
    "title": "Open Science in Big Data (OSBD) Workshop",
    "section": "",
    "text": "Back in May of this year, some of the other computer science professors and I put together a proposal for a workshop. The workshop would be in conjunction with the December 2016 IEEE BigData Conference, and would focus specifically on the intersection of big data and open science.\nIn June, we got the good news: it was accepted!\n\nWhat is “Open Science”?\nI’ve been interested in open science since I started graduate school. I’d been using Apache projects since college, learning how to set up and configure my own LAMP stack (yes, I’ll admit I dabbled in PHP for a few years, but I’m clean now!), but had never really contributed to an open source project until the 2010 Google Summer of Code. During that time, I worked on adding spectral clustering the Apache Mahout library.\nWhile open source is great and wonderful, this is just one component of Open Science. It’s another reason I’m incredibly excited about the “container revolution”: Docker and its ilk. This concept makes entire pipelines perfectly reproducible, to the point where it’s now possible for entire scientific projects to be replicated with a single command: from running the analysis, to building the figures, to assembling the final PDF file (which, by the way, can be uploaded to arXiv for everyone to read!)\nThese other aspects–open sourcing data, reproducibility scripts, and entire pipelines–are veritable educational and research gold mines, but are arguably much more difficult than simply dumping some code on GitHub. These difficulties are only exacerbated in the realm of “big data”.\n\n\nWhat are the goals of the workshop?\nThe goals of the workshop are threefold.\nFirst: we aim to identify some of the biggest challenges in democratizing big data analytics. Open Science is a critical component of both educational pedagogy and scientific research. With the increasing relevance of big data analytics, making these tools and resources available to the next generation of scientists and big data practitioners is crucial. Unfortunately, this is also extremely challenging.\nSecond: we aim to bring together big data practitioners from multiple backgrounds to discuss and establish the current state of affairs with respect to reproducibility in big data analytics and machine learning. Priorities change and constraints differ between researchers and developers in academia versus industry versus government; nonetheless, open science and big data are important to practitioners in each of these areas.\nThird: we aim to examine and propose possible routes forward to advance the continued integration of open science in big data analytics, putting tools, techniques, data, and documentation in the hands of researchers, students, and other big data practitioners. We will identify emerging trends in terms of open science best practices, and how these can be incorporated into current big data endeavors.\n\n\nWhat kinds of proceedings is the workshop accepting?\nWe hope to have two tracks: a full research paper session, and a student (short) paper session.\nPapers submitted to the OSBD workshop should, at the very minimum, have a significant Open Science component. This can take several forms, including but not limited to any combination of the following:\n\nUses free and open source packages\nOpenly available online, e.g. GitHub\nScripts are available to reproduce figures\nData are openly available e.g. dat, datahub.io\netc.\n\nWe are welcoming of original research into big data analytics, so long as there is an open science component.\nFurthermore, in the spirit of Open Science and reproducibility, we strongly encourage our presenters to incorporate live code demos, data walkthroughs, or some other hands-on activity into their talks.\n\n\nWhen is the submission deadline?\nThe deadline for workshop paper submissions is Sunday, October 25, 2016. This provides a 2-week buffer zone between the notification deadline of the main IEEE BigData conference, in case you want to repackage your conference submission for the workshop.\n\n\nWhere can one find more information about OSBD?\nWe have a website: https://osbd.github.io/\nThe website contains information about the topics around the workshop, the invited speakers who will be attending (keynote and panelists), the important dates around the workshop, and the instructions for formatting and submitting your paper to the workshop.\nWe are very excited about this workshop, and encourage you to submit! We look forward to seeing you in December!\n\n\nShannon Quinn, Co-chair\nJohn Miller, Co-chair\nSuchi Bhandarkar, Co-chair\nYi Hong, Co-chair"
  },
  {
    "objectID": "posts/2017-01-06-gameify-your-raspberry-pi/index.html",
    "href": "posts/2017-01-06-gameify-your-raspberry-pi/index.html",
    "title": "Game-ify Your Raspberry Pi",
    "section": "",
    "text": "My project over the 2016 holiday season was to take the Raspberry Pi 3 I’ve had sitting around the house idling for the previous nine months and turn it into a RetroPie-ified gaming emulator.\nRetroPie is a phenomenal bit of software that combines the work of several projects into a single package that was primarily designed to be deployed on Raspberry Pis, but which can also be set up on a regular ol’ PC. If you’re using a Raspberry Pi, it’s built on top of the Raspbian OS, so all the commands familiar to you will still be available.\nI have to say up front: the folks with RetroPie have done an amazing job. The documentation was excellent, and while I’ll walk through the installation and configuration here, with only one notable exception everything went exactly as prescribed.\n\nRetroPie\nAssuming you have all the needed hardware, installing the RetroPie OS on your Pi is pretty straightforward.\n\nUse some sort of imaging software to write the RetroPie image to an SD card (I used ApplePi Baker without any problems, but you could also just use the dd command in the Terminal, which directly moves bytes from one place to another).\nInsert the SD card into your Pi.\nBoot! I had a few false-starts that were the result of the SD card not being fully inserted, so nothing came up.\n\nIf all goes well, you should see the wonderful Raspbian logo.\n\n\n\nConfiguring RetroPie\nThe first thing you’ll need to do when RetroPie boots is to configure whatever controller you’re going to use. I went out and purchased some standard-issue Logitech USB gamepads and they seem to be functioning very well. You can also use your keyboard if you want for this, but it pretty much has to be something that can be connected via USB directly to the Pi.\nA few pointers in this step:\n\nTo skip a particular button configuration, just press and hold any button for a second.\nIf you make a mistake in configuring a button, you have to get all the way to the bottom before you can scroll back up and fix it.\nIt took me 5-6 tries to get this completely right. Just go back and do it again if you mess something up.\n\n\n\nEmulationStation\nOnce you successfully configure a gamepad, you’ll be taken to the main landing page: EmulationStation.\n\nWhere are teh gamez0rz?!1, you might be saying. Well, since ROMs are a legal gray area, you’re kinda on your own there. BUT! We have something else we need to do first anyway: set up a network configuration.\n\n\nNetwork Configuration\nIf you have a Raspberry Pi 2 or earlier, your network choices are limited to an ethernet connection. With the advent of Raspberry Pi 3s, suddenly wifi is an option! Turns out, I have a 3, and it is this wifi that caused me a couple hours’ grief until I figured out what was going on.\nGo to the wifi configuration in EmulationStation. You’ll be taken to a network selection screen–protip, the Pi 3 cannot connect to 5GHz networks–where you can select your wifi network.\nYou’ll then need to type in the wifi password. Provided you get it right, that should be it! You’re all set to go!\nIf you find yourself entering your password again…and again…and again…and again…and can’t figure out why it’s failing, read on.\n\n\nKeyboard Layout\nFor whatever reason, my keyboard was misconfigured–the layout was set to English (U.K.), resulting in some special characters being remapped. However, since the Raspbian password interface echoes stars * back, I had no idea I was typing a completely wrong password until I fired up a command prompt.\nLuckily, once you diagnose this issue, it’s fairly easy to fix. Raspbian has a utility built-in for changing your keyboard layout. You just have to navigate in EmulationStation to the option that gives you a command prompt.\nIn my case, once I had a working network connection, I just used SSH to perform any other operations on the Pi (e.g. uploading new games). The default username/password for RetroPie is pi/raspberry, which I suggest you change either from the EmulationStation main menu, or after your first SSH login.\n\n\nMoonlight on Raspberry Pi\nYou should have a working RetroPie at this point, so that’s cool!\nHowever, as awesome as the Pis are, they’re not exactly brimming with horsepower. As such, if you try running N64 or PS2 emulators, you may find as I did that anything requiring 3D shaders gets very jittery, to the point of unplayable. RetroPie has detailed configuration options for every emulator to help you get the absolute most out of your Pi, but there are some things a tiny CPU with an embedded stock GPU just can’t do, and one of those is render 3D shaders the way they were meant to be.\nSo what? Give up? Nay!\n\nMoonlight Embedded is the open source version of NVIDIA’s GameStream as used by the NVIDIA Shield. Basically, it’s a way of streaming the output of an NVIDIA GPU to another input, like a TV.\nIn this case, we’re basically turning our Pi into a glorified Chromecast–it’ll take the output from a dedicated GPU and stream it directly to the TV it’s connected to. Yes, this means you’re not actually playing games on the Raspberry Pi–you’re playing them on whatever computer has the GPU in it (oh and it has to be an NVIDIA GPU, GTX 650 or higher)–but all Moonlight requires is Raspbian, which is what RetroPie is built on!\nI found this installation guide perfect (make sure you download the latest versions of everything!), with the lone exception that, just before downloading and installing Moonlight itself, I also needed to install one more library:\n    sudo apt-get install libenet-dev\nInclude that with the other libraries installed just before Moonlight, and everything else should just work. The rest of the instructions take you through configuring the gamepads so they correctly send their input back to the GPU (so, y’know, you don’t have to sit at your computer while staring at your TV).\n\n\nHappy Fun Times!\nYes, lots of happy fun times. But also HappyFunTimes!\nIf you’re really into the party games, installing this gaming server may be the best thing ever. It’s a brilliant setup: gamepads are HTML5 canvases that run on smartphones, essentially mimicking controllers so everyone with a smartphone can play. The games range from stupidly simple to shockingly sophisticated. I may post configuration for that later, but I figure: if you’re building the Ultimate Gaming Pi, why not include that, too?\nAnd with that, I give you the results at our house:"
  },
  {
    "objectID": "posts/2019-01-31-starcraft-ii-questions/index.html",
    "href": "posts/2019-01-31-starcraft-ii-questions/index.html",
    "title": "StarCraft II Questions",
    "section": "",
    "text": "I’ve been sick the past couple of days. In between drinking way too much tea, passing out cold, and actually getting the occasional bit of work done, I’ve been (re-)playing a decent amount of StarCraft II, specifically the Legacy of the Void (LotV) campaign. It’s the final installment of SC2, and honestly it’s the one I find most frustrating.\nNo, it’s not the dialogue, which is super cliche and overwrought, but it’s endemic across the entire SC2 series. Also, the LotV gameplay honestly makes up for it (as is true for most of the SC2 series).\nRather, my problem is with the actual storytelling. There are lots of sprawling story elements but a lot of them just don’t make any sense. Heart of the Swarm (HotS) had a few chin-scratching moments, but overall the storyline was a pretty clear and well-motivated revenge tale. Even before that, Wings of Liberty (WoL) was a clear and compact story of regret and redemption. So while the LotV gameplay was outstanding, it was extremely jarring for the story to be so jumbled and reliant on retconning a large amount of StarCraft lore.\nSo may I present, inspired by RedLetterMedia’s treatment of Prometheus several years back, a list of questions that came to mind. Presented in no particular order:\n\n\nSo apparently Emil Narud / Samir Duran was also a fallen Xel’Naga, as he said as much in the LotV epilogue missions. Why was he alive all this time, but not Amon? How did he escape Amon’s fate?\nWhy did he take the form of a human instead of some all-powerful hybrid like the ones he was cultivating in those years? What was stopping Amon from taking the form of a human as well?\nWhat were the purposes of Duran’s machinations in Brood War? As stated at the time, it was in the service of returning Amon and breeding the hybrid, but if he was a full Xel’Naga, why would Amon’s resurrection even be necessary? Couldn’t Narud just remake all life in the universe, then resurrect Amon at his leisure for their post-universe-destruction celebration party?\n\n\n\nOh man, the Khala. Supposedly the thing that both saved the Protoss race back in the day, but also nearly led to their destruction when Amon infiltrated it in LotV. A nice symmetry, sure, but… ok. So. The Khala was linked through khaydarin crystals, which are rife throughout Protoss technology. The Protoss themselves interface with it through their nerve cords, which [SPOILER ALERT] they all sever at the end of LotV to drive Amon back into the Void. But couldn’t he just live on in their technology?\nWould the Protoss have to derive entirely new, non-khaydarin crystal technology to completely drive out Amon?\nHow on Kerrigan’s red Char did they manage to sever the nerve cords of literally all the Protoss of the Golden Armada–including those who had not yet arrived at Aiur–in the two minutes that the keystone was able to contain Amon?! Rohana proved that physical distance was not an issue for Amon, only connection to the Khala via nerve cords did. How could they have possibly gotten the order out to all those Protoss in such a short period?\nAmon is shown leaving Artanis’ body when Zeratul severs his nerve cords. But couldn’t Amon just possess Artanis? Why was Amon able to inhabit the Khala, but not individuals?\nI mean, where is the Khala even centralized? If it’s just the psychic connection between Protoss–and therefore completely decentralized–wouldn’t Amon act more like a virus? Why would severing everyone’s nerve cords suddenly leave Amon homeless? Is severing your nerve cords like a vaccination?\nWhy would Amon even need a “host body” if he’s able to take over literally all the Khalai Protoss?\n\n\n\nHow did Amon control the Zerg? Through an Overmind? Where was it located? If not, did he exert control over every individual Zerg? How? Why couldn’t he do the same thing through the Protoss? Or hell, even the Terrans?\nDid he possess the Zerg? Why couldn’t he control Kerrigan’s Zerg? Or again, the Protoss?\nWhere was Amon in the intervening period of Heart of the Swarm when he was (presumably) already revived following the conclusion of Wings of Liberty, but not yet the main villain at beginning of LotV? Drinking at a bar somewhere?\nThe original StarCraft lore seems to be retconned to suggest (in no uncertain terms) that any and all tampering in the development of the Zerg and Protoss was the fault of Amon and his followers and not part of the original plan put in motion by the Xel’Naga. Does that mean the Khala was Amon’s creation, as well as the Overmind? What was even supposed to happen absent the Khala or the Overmind?\nWhy was Amon so much more powerful than Ouros? They’re both Xel’Naga; wouldn’t they be evenly matched?\nKerrigan was Xel’Naga for all of an hour before she flat-out blasted Amon out of existence. How? Why was she better equipped to deal with Amon in such short order, compared to a friendly Xel’Naga trapped in the Void for eons?\nSure, maybe the combined might of both Narud and Amon kept Ouros trapped in the Void, but Narud was only with his master for all of a campaign and a half; plus, it was only after Stukov dealt Narud the killing blow in the epilogue that Ouros began the process of giving Kerrigan his essence. Wouldn’t the combined might of Kerrigan and Ouros be infinitely more powerful than just Amon?\nIf Amon killed all those slumbering Xel’Naga in Ulnar, why wouldn’t they also just return to the Void, as Amon did at the end of LotV?\n\n\n\nThe Tal’darim are introduced in WoL as a “fanatical” group of Protoss who generally do their own thing. In LotV, it’s revealed that they’re actually in league with Amon. But in WoL, they are actively fighting against the retrieval of the artifact pieces–an essential step to assembling the artifact, using it to de-infest Kerrigan, and capturing all that power to resurrect Amon. This connection becomes even more confusing when considering that it was Moebius Corps who literally hired Jim Raynor and his Raiders to assemble the artifact pieces.\ni.e., Moebius Corps was led by Emil Narud, aka Samir Duran, aka the one dude who’s been trying for millennia to resurrect Amon. Why would the Tal’darim fight directly against him? Did it take them the countless ages between the Aeon of Strife and HotS to realize they were working for the same guy?\nDo the Tal’darim still have their nerve cords? Are they connected to the Khala?\nIt would seem not, since after Alarak becomes their highlord and turns them against Amon, I would think Amon’s first course of action would be to take control of them, but he doesn’t, or can’t. But it seems like they do have nerve cords, given Alarak’s huge jagged ponytail thing. So are they somehow not connected to the Khala, despite having nerve cords? If that’s the case, why can’t the Daelaam do the same? Is it a choice to connect to the Khala? Is it like the Force–something you can train yourself to use, but which you can also consciously separate yourself from?\nAlarak is, like, wicked powerful. Crazy powerful. He breaks through a stasis field on the Spear of Adun like it was tissue paper, and blasts open an armored door and destroys a warp crystal on Aiur with a single shot. Where was that ability when he was fighting Malash for highlord?\n\n\n\nThe Nerazim are said to draw their power “from the Void”. What even is the Void? Some kind of parallel evil dimension?\nBut the Void clearly has toxic and destabilizing effects on the “current” dimension, since anytime a rift opens it pretty much wipes everything it touches apart. But then, in the epilogue, everyone gears up and heads into the Void! How?!\nSo, the Dark Templar get their power from the same place as the Xel’Naga? And Amon? Wouldn’t that mean only a Dark Templar can defeat Amon? Or that Amon could pierce Nerazim cloaks?\nOr, wouldn’t that mean Amon would have total control over their abilities, making them just as vulnerable to his influence as the Khalai Protoss?\nSeriously, how are missiles going to be an effective weapon in the Void?\nAgainst Narud and Amon?\nAMON.\n\n\n\nLet’s talk a bit about Amon’s “plan”. He wanted to break the Infinite Cycle and remake all life in his image. But the end credits of LotV literally said, that with Kerrigan’s ascension and the alliance’s victory over Amon, the Infinite Cycles came to an end. So… mission accomplished?\nSo, from the Void, he uses his pawn / follower / fellow Xel’Naga (???) Narud to work on a way to resurrect him, creating “false” hybrid armies in the meantime. Were these hybrid basically accelerated versions of what the Infinite Cycles were supposed to “naturally” result in? I mean, weren’t the Zerg and Protoss ultimately meant to merge?\nAmon corrupted the Zerg, creating an overriding imperative to destroy or assimilate the Protoss. Since the Protoss can’t be infested, I would assume that basically amounts to a “kill” order?\nAnyway, the Overmind cleverly tries to circumvent that order by creating the Queen of Blades, with supposedly only slightly more free will than it. Why? Where does that slightly-more-free-will come from? Just because she’s Terran, and therefore not a Xel’Naga creation? Or was it something unique to Kerrigan?\nOf course, she was only infested after Amon’s death. How was Narud/Duran planning to resurrect his master, then? It was only the de-infestation of Kerrigan that gave him enough power to resurrect Amon. So until that unlikely sequence of infestation-deinfestation events happened, had he just been spending a lot of time on his Pelaton and researching cutting-edge battery technology?\n\nReally, I just think this game sucks.\n(not really tho)\n\n\n\nCitationBibTeX citation:@online{quinn2019,\n  author = {Shannon Quinn},\n  title = {StarCraft {II} {Questions}},\n  date = {2019-01-31},\n  url = {https://magsol.github.io/2019-01-31-starcraft-ii-questions},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2019. “StarCraft II Questions.” January 31,\n2019. https://magsol.github.io/2019-01-31-starcraft-ii-questions."
  },
  {
    "objectID": "posts/2018-01-19-new-years-resolutions/index.html",
    "href": "posts/2018-01-19-new-years-resolutions/index.html",
    "title": "Resolutions for 2018",
    "section": "",
    "text": "A solid three weeks late on the new year’s resolutions, but still a marked improvement over last year.\n(…I didn’t post resolutions last year…)\nI’ve been involved with a small faculty writing group since mid-December, with the expressed goal of helping its participants develop and sustain regular writing habits. Since any new resolution’s long-term success is pretty much exclusively contingent on whether or not a habit is formed, I’m also trying to eliminate some bad habits (since new habits are easier to form if they, in effect, take the place of the bad habits).\nSo without further adieu (and with a bit of inspiration from Dr. Albert), here are my 2018 resolutions:\n\nWrite and/or edit every single day (operationally I’m aiming for at least 30 minutes/day, 5 days/week, and go from there).\nBlog more frequently. Despite starting this cool pelican blog back in 2015 for the expressed purpose of basically doing what Jake VanderPlas does on his blog–but with my research–I have yet to really bring that idea to fruition. That changes this year.\nMake some progress on a few fun side projects!\n\nThere are quite a few side projects that have languished over the last several months (changing this blog’s layout was one). I’d love to actually finish one!\n\n\n\n\nCitationBibTeX citation:@online{quinn2018,\n  author = {Shannon Quinn},\n  title = {Resolutions for 2018},\n  date = {2018-01-21},\n  url = {https://magsol.github.io/posts/2018-01-19-new-years-resolutions/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2018. “Resolutions for 2018.” January 21,\n2018. https://magsol.github.io/posts/2018-01-19-new-years-resolutions/."
  },
  {
    "objectID": "posts/2016-05-16-autopost-running-twitter-summary-strava/index.html",
    "href": "posts/2016-05-16-autopost-running-twitter-summary-strava/index.html",
    "title": "A twitterbot for posting weekly running stats",
    "section": "",
    "text": "We runners (we’re a crazy bunch), for the most part, like our stats. How many miles do you log each week? Each month? How are your average race paces trending? Are your long runs both feeling good and getting faster?\nYes, we’re a little obsessed with our numbers.\nIt’s no surprise, then, that web services have popped up to help us aggregate some of these numbers. One of the most obvious is Garmin Connect, home for pretty much anyone who uses the Garmin GPS watches.\nAnother that I’ve used before is Daily Mile. However in recent months I’ve become frustrated enough with the site to leave entirely. By all accounts, no part of the site has been updated in years, and other alternatives are simply much more pleasant to use.\nUnfortunately, there was one crucial feature of Daily Mile I really liked: connecting it to your Twitter account to post weekly summaries of your recorded workouts. I liked it so much, in fact, I created a small web service to do the same thing, but for monthly summaries:\n\nObviously that service no longer exists, but ever since I’ve been wanting to get something similar up and running again. Especially now that I don’t even have weekly summaries anymore–just couldn’t stomach Daily Mile any longer–I wanted to take the opportunity (and the shiny new blog) to go through a step-by-step procedure of creating your own Twitter / Strava app for posting weekly summaries on Twitter of your running mileage!\n\nPreliminaries\nA few things you’ll need before we get started:\n\nPython 3.5\ntweepy (for interfacing with Twitter)\nstravalib (for interfacing with Strava)\npybot (shameless plug, but it will help)\n\nBoth Twitter and Strava use OAuth as their method of app authentication. These libraries just make it easier to interact with the services; they abstract a lot of the details of authentication and communication.\nBut in case you’re interested: Twitter’s docs and Strava’s docs.\n\nStep 1: Create a Strava app\nGo to your user settings and create an app that can interface with your account. Important pieces of information you’ll need later: Client ID, Client Secret, and Your access token.\nWe can test if it works. Fire up an IPython terminal, get your access_token, and run the following code:\n    from stravalib import Client\n    client = Client(access_token = access_token)\n    client.get_athlete()\nYou should see something along the lines of:\n    Out[]: <Athlete id=1234567 firstname=b'Firstname' lastname=b'Lastname'>\n\n\nStep 2: Retrieve last week’s data\nThe whole point is to get weekly mileage reports. Thankfully, the get_activities method in stravalib has an after optional parameter we can use to precisely tune what time interval we want.\nFirst, though, we need to create a timestamp that represents the 1-week time frame. If we assume this will only be executed on the day we want the summary–say, every Monday–then we need to tally up all the runs from the day before all the way back to the previous Monday, inclusive.\n    import datetime\n    current = datetime.datetime.now()\n    last_week = current + datetime.timedelta(weeks = -1)\n    after = datetime.datetime(last_week.year, last_week.month, last_week.day)\n    activities = client.get_activities(after = after)\nAssuming we run this chunk of code on a Monday, it should give us every Strava activity from the previous Monday up to the present.\nHowever, we’re not done yet. This includes everything–not just our runs, but any other activities that we recorded; yoga, weights, elliptical, and so on. We need to filter these out. We also need to filter out the edge case of any activities that have been recorded today, since we don’t want to include these in a report of last week’s activities!\n    l = [activity.id for activity in activities if activity.type == 'Run' \\\n        and a.start_date_local.day != current.day]\nOk, let’s pause and discuss what’s happening here.\nFirst, the most obvious: we’re looping through the activities generator we obtained in the last line of the previous step. Second, the if statement at the end filters out any activities that aren’t a run. Finally, the activity.id part out front says, we’re building a list of the unique IDs that identify each activity. The last part is our timeframe edge case: if we recorded an activity today, even a running activity, don’t include it.\nWhy are we only holding onto the IDs? It has to do with detail. Strava maintains a hierarchy of details available to users that vary with authentication, connection, etc. Simply put, when we request a list of activities, the default detail level is 2, which is “summary” level. However, some of the metrics we need–calories in particular!–require level 3, or “detailed”. To get this level of detail, we need to query for individual activities…one at a time.\nHence, a list of activity IDs! Now we can loop through the IDs, requesting details on each run and tabulating up the mileage and calories.\n    from stravalib import unithelper\n\n    mileage = 0.0, calories = 0.0\n    for activity_id in l:\n        activity = client.get_activity(activity_id)\n\n        # This is annoying; all the default distances are in meters! Luckily,\n        # stravalib comes with a nice unit helper utility to do the conversion.\n        distance = unithelper.miles(activity.distance)\n        mileage += round(distance.num, 2)  # Rounds to 2 sig figs.\n        calories += activity.calories\nThere you have it! In those two variables–mileage and calories–you have all the data you need to summarize your running workouts for the last week. Now we just need to post this information on Twitter!\n\n\nStep 3: Create a PyBot\nOk, time for a shameless plug: yes, I’m the pybot author. It’s still highly experimental, and largely uncompleted, but for our purposes it will suffice nicely as a barebones framework to interact with Twitter.\nClone the repo and follow the setup script to create a Twitter app and connect it to your account.\n    git clone https://github.com/magsol/pybot.git\n    cd pybot\n    sbin/create_pybot.py\nThat will walk you through the instructions for creating an app, generating OAuth credentials, and stubbing out your first pybot. Feel free to give it whatever name you’d like; for the purposes of this tutorial, I’ll assume we’ve named it artbot (don’t ask). Congratulations! You’ve created a twitter bot!\n\n\nStep 4: Customize the bot’s behavior\nOur bot is pretty simple: every Monday at some specified time, it will wake up, read all the prior week’s running activities, and post the summary before going back to sleep for another week.\nIt won’t be prompted by anything other than time. So the specific action override we’re looking for in PyBot parlance is on_tweet, and the interval we’ll use is tweet_interval. The latter is easy enough–a full week between tweets!\n    self.config['tweet_interval'] = 60 * 60 * 24 * 7\nBefore we go any further: does anyone see anything wrong with the above code snippet?\nI’ll give you a hint: imagine you started this bot on a Tuesday, instead of a Monday.\nYep, there it is. This interval we’ve defined is exactly 1 week, but it doesn’t account for when we actually START the bot. We need this to be a little more intelligent. If you want the posting to happen weekly every Monday, it shouldn’t matter when you actually start running the bot, right? It should be smart enough to figure out when it needs to post for the first time, then post weekly thereafter.\nA neat component of PyBot is that, in addition to giving hard time frames, you can also specify functions to compute the interval on-the-fly, subject to some other constraints that are dynamic (like on what day of the week you happen to fire up the bot).\nTo make things easy on us, we’ll use the datetime convention in the Python documentation for identifying individual days of the week. This tutorial assumes Mondays (which corresponds to 0), but you can use whatever value you want.\nWe need to store this as a configuration parameter in the bot.\n    # Put this somewhere in the bot_init() method\n    self.config['update_day'] = 0  # Corresponds to Monday.\nNow, we need a function to compute the interval between updates.\n    # Put this somewhere in the bot_init() method\n    self.config['tweet_interval'] = self._compute_interval\nWe’ve referenced an internal method we’re calling _compute_interval, as of yet undefined. Let’s go ahead and define it!\n    # Put this somewhere in the bot class declaration\n    def _compute_interval(self):\n        interval = 60 * 60 * 24 * 7  # The default interval; we'll start here\n\n        # Are we on the right day of the week?\n        now = datetime.datetime.now().weekday()\n        target = self.config['update_day']\n        if now == target:\n            return interval  # Nothing to do! Yay!\n\n        # If we get to this point, it means the index of the current day--\n        # as in, right when the code gets HERE--doesn't match the index of the\n        # day we've said we want to perform this update. So we need to do a\n        # little bit of work to compute that date.\n\n        if now > target:\n            # This is a hack, so the index of the CURRENT day will always be\n            # smaller than the index of the TARGET day.\n            now -= 7\n\n        # Essentially, all we've done is replace the 7 above with whatever\n        # it needs to be in order to get us to our target day.\n        return (target - now) * 24 * 60 * 60\nNow that our interval is in place, we’ll need to override the on_tweet action to do what we want whenever it’s called (which will be once each week on the day we’ve specified!). Remember, this method is called once we’ve hit our interval. So this is where it all comes together!\n    def on_tweet(self):\n\n        # First, pull in the stats from Strava.\n        current = datetime.datetime.now()\n        last_week = current + datetime.timedelta(weeks = -1)\n        after = datetime.datetime(last_week.year, last_week.month, last_week.day)\n        activities = client.get_activities(after = after)\n\n        # Second, filter by activity type and time frame.\n        l = [activity.id for activity in activities if activity.type == 'Run' and\n            a.start_date_local.day != current.day]\n\n        # Third, tabulate up the stats for mileage and calories.\n        mileage = 0.0, calories = 0.0\n        for activity_id in l:\n            activity = client.get_activity(activity_id)\n            distance = unithelper.miles(activity.distance)\n            mileage += round(distance.num, 2)  # Rounds to 2 sig figs.\n            calories += activity.calories\n\n        # Finally, use the stats to craft a tweet. This can be any format\n        # you want, but I'll use the example one from the start of the post.\n        tweet = \"My training last week: {:d} workouts for {:.2f} miles and {:d} calories burned.\".format(len(l), mileage, calories)\n        self.update_status(tweet)\nThat’s it! You have everything you need; now, just set the bot to run ad nauseum:\n    python artbot.py\nIt should run forever, sleeping for most of it but waking every week to post your summary. If you notice something isn’t working right, check the logs; they should specify if there are problems e.g. with permissions posting to Twitter, or connections hanging and disconnecting.\n\n\n\nConclusion\nThat’s all there is to it! There are obviously a lot of technical hurdles I largely glossed over–creating the apps for both Strava and Twitter can be a little more involved than the average person would like, and Python versions (especially 2.x vs 3.x) can wreak havoc on your code. I tried to be as reproducible as I could, though until Jupyter notebooks decide to play nice with Pelican (or maybe the other way around?) these code embeddings will have to suffice. Sigh.\nPlease feel free to leave a comment if you have any questions! I’ve also posted the bot in the examples folder in the pybot GitHub repository as artbot.py. Happy tweeting!"
  },
  {
    "objectID": "posts/2018-01-06-new-year-new-blog/index.html",
    "href": "posts/2018-01-06-new-year-new-blog/index.html",
    "title": "New year, new blog layout",
    "section": "",
    "text": "Happy 2018!\nI’ve been wanting to put a fresh coat of paint on things for awhile around here, especially since the old Flex template didn’t have a really good way of supporting embedded Jupyter notebooks without completely upending the CSS (love the theme otherwise!).\nTaking a page (or really, an entire layout) from Jake’s blog, I can now embed Jupyter notebooks without trashing the whole layout of the site. There are some posts I’ve been wanting to make for awhile that will require a considerable amount of code, so I’m excited to be able to dig into them now!\nI’ll be following up soon with a lengthier resolutions post, but for now I just wanted to say “I’m still alive” and roll out the new layout. Happy new year everyone!\n\n\n\nCitationBibTeX citation:@online{quinn2018,\n  author = {Shannon Quinn},\n  title = {New Year, New Blog Layout},\n  date = {2018-01-06},\n  url = {https://magsol.github.io/posts/2018-01-06-new-year-new-blog/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2018. “New Year, New Blog Layout.” January\n6, 2018. https://magsol.github.io/posts/2018-01-06-new-year-new-blog/."
  },
  {
    "objectID": "posts/2015-11-07-introductions/index.html",
    "href": "posts/2015-11-07-introductions/index.html",
    "title": "Introductions",
    "section": "",
    "text": "Well, this seems to be working. Kinda.\nI took some inspiration from Jake VanderPlas’ Pythonic Perambulations and opted for a similar route: Pelican as the backend blogging machine, github as the host, and (eventually) embedded Jupyter notebooks. Unfortunately, Jake’s addition to the Pelican plugins to allow Jupyter notebooks uses CSS that is, shall we say, unfriendly to Pelican themes outside of the Octopress default.\nSo that part is still incomplete. As are many of the links and some of the plugins. But ultimately, I’m hoping to use this to supplant my current pair of blogs that jointly detail what my plan for this space is: academia, general data science, and other musings.\nStay tuned!"
  },
  {
    "objectID": "posts/2017-05-31-summer-of-data-science/index.html",
    "href": "posts/2017-05-31-summer-of-data-science/index.html",
    "title": "Summer of Data Science 2017",
    "section": "",
    "text": "A few days ago, while I was still in Portland, OR enjoying the last few days of PyCon 2017, Renee (@BecomingDataSci) mentioned on Twitter that she might bring back the “Summer of Data Science” she kicked off last year.\nIn short: use the summer as an opportunity to learn and/or accomplish something data science-related in a goal-oriented, data-driven way.\nAs a tenure-track professor still yet to endure the 3rd-year review, pretty much everything data science related revolves around furthering my eventual tenure dossier. But the summers are still considerably more flexible for me to accomplish some of these goals than the fall or spring (I love teaching, but it’s all-consuming). I also have more than just myself–networks of collaborators and research assistants who can help me with these goals.\nSo without further adieu, I’d like to put forth my own Summer of Data Science, 2017 Edition:\n\nTeaching: 1360E improvements and 4360/6360 preparation\nI’m teaching an online course this summer, starting June 5 and continuing through the end of July: CSCI 1360E Foundations of Informatics and Analytics.\nOr, more colloquially, I just call it “introduction to data science.”\nIt’s one of the five courses I proposed in my first year (a story for another time, believe me…) and taught for the first time last summer, and in-person last fall. I’m teaching it again this summer and hoping to make some of the standard improvements, such as sprucing up slides and fixing autograder bugs from previous incarnations.\nMore pressing is CSCI 4360/6360 Data Science II, which has yet to have its own website. This course has never been taught, but is slated for Fall 2017.\nDid I mention there are already over 40 students registered, undergraduate and graduate combined?\nThis is supposed to be the “corner cases” of data science: lesser-used and/or more powerful analysis methods that aren’t necessarily the first tools or techniques you reach for in a given situation. This will include, but certainly not be limited to, concepts like randomized algorithms, semi-supervised learning, and backpropagation; techniques like out-of-core processing, distributed computing, and functional programming; tools like Julia, numba, and dask.\nBefore you ask: No. I’m not covering Spark.\nAt any rate, the conceptual framework is in place, but practically none of the architectural logistics have been established. So this will take up virtually all of my time for the remainder of the summer, once the following item is completed…\n\n\nResearch: NSF CAREER proposal\nThe advantage of this goal is it has a hard end date: July 19.\nThe disadvantage is that the NSF CAREER is the pinnacle of NSF early-career investigator awards. Its importance cannot be overstated; its je ne sais quoi is on display in the faces of new investigators when you mention it around them.\nI’ve connected with my university’s grant proposal officers, and am participating in a peer review process that involves two rounds of review: first with fellow CAREER submitees (as in, we exchange each other’s current drafts!), and second with the university grant officers.\nAn investigator can only make three submission attempts for the CAREER. The CAREER is only open for submissions once per year. If chosen, the investigator must still be un-tenured at time of award. These conditions place brutal limits on how long you can wait to start making submissions, and I already skipped submitting my first two years. Still, I have no illusions about the uphill battle I have, so my goal this first time around is simply to acquire feedback: from my peers, from my grants officers, and from the NSF reviewers.\n\n\nPersonal: Coursera’s optimization course\nI signed up to take Coursera’s Discrete Optimization course out of the University of Melbourne, taught by none other than Professor Pascal Van Hentenryck at Michigan and Dr. Carleton Coffrin, currently at Los Alamos.\nOptimization is pretty much the backbone of modern machine learning, and yet I have almost no formal training in it–beyond incidentally covering it in various machine learning and statistics courses as part of some broader topic in which it’s used. Oddly, the most rigorous instruction I received as a graduate student in optimization was a Cell & Systems Modeling course where we used various optimization techniques to find parameter values for population models.\nEspecially in conjunction with what I hope to teach in CSCI 4360 in the fall, this would be invaluable both professionally as well as personally."
  },
  {
    "objectID": "posts/2017-03-16-so-you-want-to-conduct-research-with-me/index.html",
    "href": "posts/2017-03-16-so-you-want-to-conduct-research-with-me/index.html",
    "title": "So, you want to conduct research with me?",
    "section": "",
    "text": "Deviation #1: This is wholly separate from the “should I get a Ph.D.” question. For that I would recommend one of numerous guides that ask all the right questions.\nDeviation #2: This is also wholly separate from how to succeed in a Ph.D. program, though there is some overlap. In general, there are some key items to consider and habits to build as you work your way through a Ph.D., and for those questions I highly recommend Andrej Karpathy’s excellent survival guide to a Ph.D., some of which may be mirrored here.\nNo, the specific question I’m addressing here is how to succeed in graduate research as one of my students. In order of somewhat-importance:\n\n1: Familiarize yourself with my research interests.\nThis may seem like a no-brainer, but you’d be surprised how many emails I get from individuals expressing profound interest in working with me, only to see they have i) no experience whatsoever in any of my interests (which isn’t necessarily a deal-breaker!), and ii) don’t appear to know what I work on (which is a deal-breaker). If you work with me, you’re going to do something at the intersection of bioimaging + distributed computing + biosurveillance; something that involves computer vision and machine learning in a public health setting.\nCheck out my Google Scholar record, my group’s GitHub repositories, and my lab website to get at least a basic idea of the sort of work I do, and to jog your thinking along the lines of what you might be able to contribute.\n\n\n2: Take into consideration the following expectations.\nWork hard, play hard, and be able to talk about both:\n\nI expect my students to develop into excellent scientific communicators. In practice, this means I want you to be able to talk about your work to experts in the same field, experts in different fields, and even non-scientists. I want you to get comfortable giving talks and writing papers. If English isn’t your first language, that’s ok! Just be aware this expectation may take more time than you think.\nI expect my students to participate in Open Science. In practice, this means I want you to publish all the code you write in public repositories, mirror all your papers on arXiv, participate in and contribute to open source projects, and maybe even contribute to a blog. Research is only interesting when you can pick through the code, explore the data, and regenerate the results. Know or learn how to use scientific notebooks, version control, wikis, and even containers!\nI expect my students to demonstrate a promising slope of accomplishment. Put simply, I recruit for potential (slope), not experience (y-intercept). You don’t have to know everything about machine learning, statistics, and linear algebra, and be an expert programming in Python just to be able to work with me. However, I do expect that you will be able to pick up these skills very quickly.\nI expect my students to take ownership of their projects, pushing the envelope of what is known and beyond what even I would suggest.\n\nSpeaking of which…\n\n\n3: Prepare yourself to be a self-sufficient researcher.\nThis does NOT mean I expect you to do everything! The whole point of being a student is that you have a mentor, a supervisor who is (in theory) more experienced than you, from whom you can learn. It is indeed my job to guide you and teach you what I know, and I will most certainly do that.\nThis DOES mean that, by the end of your time here, I want you to be the expert on your project! You should take the project and run with it, rather than wait for me to tell you what to do next. Build your intuition about the problem through “moving fast and breaking things,” to use the tech startup parlance. Ask forgiveness rather than permission. Insert witticism here that basically says KEEP TRYING THINGS.\nEven as you start your project, you may come across roadblocks that I don’t have an answer for. That’s how research works: we’re pushing the limits of our collective knowledge! I may have some intuition from previous problems, and I’ll certainly share that, but asking me “What do I do next?” is going to frustrate both of us very, very quickly.\nHere’s another example: the levels of data science classes. You don’t have to be anywhere above Level 2 when you arrive (maybe you’re still working your way through Level 1!), but I expect you to work through Level 7 by the time you leave.\n\n\nIf you’ve made it this far, and are still interested…\n…then I encourage you to reach out to me and express your interest! I have just a few final pieces of advice:\nFirst, read this brief Twitter thread and this brief Twitter thread as well.\nNext, do NOT send me\n\na form email with a 10-page summary of your accomplishments (as I said, I don’t hire for y-intercept, I hire for slope)\nan email with misspellings or grammatical errors (recall that I emphasize good scientific communication skills)\na message that starts with “Dear Ms Quinn” (first, I’m a doctor; second, I’m a guy)\n\nI won’t respond.\nFinally, write an email that’s 3-5 sentences at most, with a specific mention of the work you find interesting and want to pursue further. For extra credit, mention some kind of improvement or extension to the work that you came up with on your own. This tells me a lot of things all at once, most important of which is that you’re serious about wanting to work with me.\nBecause if you can handle graduate school…\n\n…I really do believe you can handle anything."
  },
  {
    "objectID": "posts/2018-04-26-jedi-outcast-echoes-of-a-bygone-gaming-era/index.html",
    "href": "posts/2018-04-26-jedi-outcast-echoes-of-a-bygone-gaming-era/index.html",
    "title": "Jedi Outcast: Echoes of a bygone gaming era",
    "section": "",
    "text": "I should start by issuing fair warning: this is a post I’ve been meaning to write in some form or another for the better part of the last 15 years.\nCommence “old mang” jokes.\nBut there was a group of gamers I met many years ago who, to this day, remain some of my best friends. We don’t keep in near-daily contact like we used to, but it doesn’t take more than a couple friendly jabs to pick up right where we left off. Particularly at a time when I feel very alien and removed from the gaming community, both by virtue of stage of life as well as events of late, I want to hold up a sliver of the gamer’s experience that, at least for me, was phenomenally positive and formative.\n\nJedi Outcast\n\n\n\nSource: https://www.gog.com/game/star_wars_jedi_knight_ii_jedi_outcast\n\n\nThe entire story essentially revolves around a video game: Jedi Knight II: Jedi Outcast. But while this seemingly-innocuous run-of-the-mill Star Wars game was the central impetus, its unique properties–which I can honestly say haven’t been replicated in more recent games–gave rise to a community that still impacts me to this day.\nJedi Outcast, colloquially referred to either as “JK2” or “JO”, is a first-person shooter that continued the adventures of Kyle Katarn started in the original Dark Forces and carried forward in Jedi Knight. It was, far and away, the finest installment of the series.\n\nJO came with a single-player campaign that involved an attempt by a fallen Jedi to harness Force energy in order to artificially infuse his warriors with the Force, essentially creating dark Jedi on-demand. It was quite engaging! But the real novelty, and probably the most unexpected success, was the multiplayer.\nI mentioned before it had some unique properties that gave it its staying power. Among others, and in no particular order:\n\nIt was the first game in the series to feature truly immersive lightsaber mechanics. Dark Forces II had introduced lightsabers, but to wield it was essentially like watching a monkey hit something with a stick. JO made it look like it came out of a movie.\nThe Force powers were also considerably better-integrated with gameplay. Again, Dark Forces II had pioneered Force powers, but they were clunky in their use; in fact, you could beat the single player without ever using a single one. JO seamlessly wove their use into the game.\nThe developers open-sourced the server-side JO code almost immediately after release, prompting the explosion of a modding community around the game, building everything from new in-game characters to new multiplayer maps to entire server mods.\nThe multiplayer enabled what we affectionately referred to as a “chat room with a GUI”: an environment where players could shoot and duel, but also literally stand around talking.\n\n\nIn the picture above, the dark text boxes you see above some players heads are the tell-tale indicators that the player is typing a message. Meanwhile, battle can literally rage around them.\nAll this gave rise to an environment conducive to the formation of “gaming clans”: communities of fellow gaming nerds who enjoyed the game and the people in it. Numerous clans popped in and out of existence, with as many varieties of names and purposes and values as individuals on the planet.\nHere’s where I entered into things: my story begins in the fall of 2003, when I was just starting my first semester as a freshman at Georgia Tech.\n\n\nFall 2003\nI’d been the proud owner of a JK2 CD-ROM for a year or so at that point, but hadn’t had a desktop powerful enough to play it. Now, armed with a brand-new Dell Optiplex with a 3GHz processor and 4GB RAM, I had enough horsepower to give the game a test drive.\nOh yeah, and also study Computer Science at one of the finest institutions for the field in the world. But I digress.\nI devoured the single-player JO campaign, loving every minute of it. But when it came to the multiplayer, I was very hesitant. I remembered all too vividly the frantic competitiveness of multiplayer StarCraft from high school–I’d been ranked in the Top 1000 at one point, but pretty much to the detriment of my sanity–and really didn’t want to get similarly sucked into an anxiety-inducing hyper-competitive environment where, at the end of the day, all I had to show for my hours sunk into the game was a migraine.\nWell, I could say one thing for sure: I was nowhere near as good at the multiplayer as I’d thought I was from the single-player. I got my ass handed to me. A lot. But another thing I quickly learned: the vast majority of the folks playing this game were chill. The whole “chat room with a GUI” thing.\nSoon, I fell into an online clan, called “Imperial Forces”. But my courtship with the clan was extremely brief: evidently, any bad clan can have one decent person in it, and after a very short membership–maybe a week?–I departed its ranks.\nAnd discovered the “Power of Thee.”\n\nYes, it was indeed “cleverly” titled to invoke a particular acronym. But beyond the name, it was the people: every single one of them was both super-chill and super talented. I could tell there was considerable variation in age, both younger and older than me, but they were wholly welcoming. And so freaking good.\nLucky for me, they recruited me. But like any good Jedi organization, new recruits–apprentices–are assigned a master. My master was a veteran of JO, a Knight named Kaleb. He helped me learn the intricacies of the game, as well as the “protocols” that had arisen around the GUI-ified chat room of JO, things like\n\nIf someone has a chat window above their head, don’t attack them\nWith great [admin] power comes great responsibility\nDon’t take things too seriously, otherwise you’ll get C4’d\n\n\nAt some point, I was deemed ready for my “Trials”. Apprentices such as myself pass their Trials and become full members of the clan by winning at least 4 out of 6 lightsaber duels with Knight-level members or higher. I don’t remember my exact record–I don’t mean to toot my own horn, but it very well might have been 6-0 (Kaleb was a great teacher!)–but I passed my Trials and was duly Knight-ed into PoT.\n\n\nSpring 2004\nTo provide a bit of context: JO was released in 2002. So right as I was hitting a stride with my new clan and actually git good at multiplayer, the game had already been out for over two years. And on the “clan” scene, two years is an eternity. There were senior members of PoT–the “Council” members, including the original founders–whom I’d never met because they’d already moved on, essentially having gone permanently inactive. The active membership–Knights who’d passed their Trials and made up the bulk of the active membership, and Jedi Masters who were promoted from Knight by virtue of some outstanding contribution to the clan–kept things fresh by recruiting new talent.\nBut the gears of time ground on. Spring 2004 was a particularly rough time for me personally, as I settled into my second semester of college and I was caught somewhere between who I’d been in high school and who I wanted to become as I moved into adulthood. My roommate, a dear friend from high school, was also going through some really hard times and ended up dropping out halfway through the semester, so I ended up being alone more often than not.\nAt the risk of sounding melodramatic, JO and PoT was an anchor; I was getting to know my fellow clanmates better, chatting with them directly over AOL Instant Messenger instead of exclusively through JO. Getting to know them as people, rather than avatars. Sharing experiences. It… helped. In more ways than I can recount, even now.\nBut that anchor was shifting in ways I hadn’t been around long enough to realize.\n\n\nSummer 2004\nIn many ways, this was one of PoT’s strongest seasons. In others, it was almost its end.\nI’d (somehow) secured an internship at an Atlanta-based supply-chain company, but because they had no idea what they wanted me to do, I found myself with a lot of free time.\nSo I exercised some of the new network connections I’d made through JO and organized an inter-clan match: a day-long competition between PoT and They Might Be Jedi, or TMBJ.\n\nTMBJ was the JO clan. Everyone wanted to join them, and failing that (which was often), wanted to be them. They were kind, they were competitive, and they were good at everything. Their most famous member went by the handle “ShroomDuck”, and he was a singularly talented individual who was equal parts charming in person, deadly with a lightsaber, and wicked talented with JO modding tools, Photoshop, and web design.\nBasically, a bit of a personal hero at the time. So, I submitted a challenge to TMBJ through him and on behalf of PoT to engage in a bit of well-mannered duels to the death.\nGuess what? We won!\n\n\nTMBJ was stacked with talent, but somehow our own cohesiveness and teamwork–led by the inordinately talented likes of IronSlayer, Bill the Pony, Rob, John, Vader, and my master Kaleb–bested the JO juggernaut that day.\nThen, mere weeks later, it all came crashing down: pretty much every one of those individuals announced that, for various reasons, they were leaving. We all knew it wasn’t coincidence they were all leaving at the same time, but as I was still a Knight at the time and not privy to the discussions of the Council (to which Kaleb had been promoted since), I didn’t have any details.\nSuddenly, we were a shell of ourselves: the 5-6 people who comprised a good 75% of the clan’s activity were gone.\nI’ve been told before–by coaches, by therapists, by parents, and by my wife–that I don’t know how to quit. It’s not always meant as a compliment, either; there are times when you really should cut your losses and walk away. I’ve learned how to do that more as I’ve gotten older, but suffice to say, my 19-year old self knew little to nothing of that skill.\nSo I dug in. Over the next several months, I configured my own server to use for PoT (IronSlayer had run our local server until then), helped revamp the clan website, and advertised the clan whenever I was in-game. I sought out contacts I’d made in-game and brought them to our servers, increasing the baseline activity level that would attract more new blood. I relentlessly badgered the shattered Council with ideas, initiatives, and new recruits, insisting the new blood was there if I could just have permission to recruit them.\n\n\nFall 2004\nTo their credit, after the initial shock wore off (and with some prodding on my part), the Council got down to work. I was quickly promoted to Jedi Master, and in short order, instated on the Council to fill the open seats left by the departures of the previous season.\nKaleb had a made a 1-year anniversary graphic back when he’d still been in the clan, so I followed suit as both a tribute to someone who’d taught me everything and also as a nudge to everyone else that I wasn’t going anywhere, and neither should they.\n\nYes–I even learned from Kaleb how to make custom player skins. I wasn’t nearly as talented as he was, as I basically applied minor tweaks to a default built-in skin, but I was awfully proud of the “PoT” shoulder and thigh logos, the shamrocks on the calves, the lightning bolt across the chest, and the giant “69” emblazoned on the back.\n\nOur ranks started swelling again. Too fast on occasion, even; we had to shut down recruitment at times in order to fully process applications and keep some semblance of order on our servers. Some of the best friends I made through PoT either appeared during this time, or the circumstances were such that an acquaintance deepened into a friendship.\n\nRob was this way: a total goofball who was one of the best “gunners” (term for a JO player who preferred the point-and-shoot weapons to lightsabers) I’d ever encountered. To the casual observer, he and I appeared almost as opposites: I was all about structure and regimen; he just wanted to shoot at something and crack jokes. But when we were both promoted to the Council in the wake of the summer departures, against all odds we worked extraordinarily well together, our differing styles complementing each other and resulting in a friendship that endures to this day.\n\nTahiri was another. He always kept a veil of secrecy around him, in no small part because his in-game avatar was female (his name “Tahiri” follows an Extended Universe character by the same name, who is female as well). But over AIM I learned he was a mere year older than I was, and as we worked closely to keep PoT alive in that summer and fall of 2004, we forged a relationship similar to the one I had with Rob, with the roles reversed: I kept him from being too rigid, and he kept me from being too slapdash.\n\n\n2005\nWe continued recruiting, and I even managed to snare my literal Best Man, The Danimal.\n\nOur renewed membership enabled us to engage in more inter-clan matches. We even managed to win a few of them!\n\n\n\nDidn’t do so well here–if TMBJ was #1, UJ was #2. Especially in saber duels, they were unstoppable.\n\n\n\n\n\nNJOC was a much smaller clan, and through a rigorous practice regimen in the weeks leading up to the match, we actually ended up winning!\n\n\nI do want to mention something here, given Kaleb brought it up in his blog post some months ago: the Delta Order.\n\nIn the intervening months after the departures of mid-2004, it was clear–especially from the matches–that PoT was seriously lacking in gunning talent. Rob was still among the best I’d ever seen at any point in the game, but if he wasn’t around, we really had nobody who could even come close to matching his play level. I was getting better, but again we really didn’t have anyone else who was a pure gunner.\nDelta Order was an attempt to remedy that: Rob and I would work together to groom younger members who demonstrated a knack for gunning to be the next Rob, essentially. It wasn’t meant as a super-secret infiltrate-clans-from-within, CIA-like operation. Admittedly, we could have just as easily had a regular low-key practice session for anyone who wanted practice shooting things, but we thought this might make it more “official” and interesting to the younger players if they got a cool logo to go with their training efforts.\nIt worked, somewhat: we trained Monkeh into one of the finest gunners in the clan (outside Rob, of course), and brought a lot of other players’ skills more into parity with the general audience of the game. It was partially thanks to the Delta Order that we ended up winning the aforementioned match against NJOC.\n\n\n2006\nAt some point, we started organizing intra-clan matches in the form of summer tournaments. These were a blast!\nWe made entire brackets, and organized two separate double-elimination tournaments: one with best-of-three lightsaber duels, and the other with first-to-15-kills run-and-gun duels, appealing to the two flavors of JO player.\nThe response was overwhelming, and was a huge boost to the clan. Though to this day, I’m stll not sure how Rob of all people won the lightsaber competition. I think I just forgot to fill out the rest of the other bracket, but am pretty sure that was the year Rob won both competitions. WTF?\n\n\nSomewhere in here, I colluded with a couple of my friends in PoT to stage an April 1 trick where we would all announce our immediate retirements from PoT. Tahiri wasn’t pleased. Note the shift as he starts with sheer panic, then later after reading an “April Fool’s!” follow-up post, shifts to relief with some good-old-fashioned ribbing.\n\nWe were having a lot of fun. I’m glossing over a lot–there was intra-clan drama, clashing of personalities, and the Council (myself included) made a lot of noob mistakes in handling them–but for all intents and purposes, the clan was humming along.\n\n\n2007\nFor all practical purposes, this is where my role in PoT–after a solid four years–started waning. I was entering into the last year of my undergraduate studies at Georgia Tech and eyeing graduate school, was in a serious relationship that I was trying to convert from long-distance to short-distance, and JO was really starting to show its age: fewer new players were appearing, and more experienced hands were leaving. While we still technically had a full complement on the Council, only three of us–Rob, Tahiri, and myself–were still active in any meaningful capacity. Our Jedi Master ranks were pretty thin, and while we had many active Knights, our apprentice prospects were drying up.\nIn short, it was time to start having difficult conversations: PoT, at least in its current form, wasn’t going to last forever. And that end was looking to come sooner and sooner.\nIn the months that followed, a lot of options were thrown out, from continuing as we were to converting into a less formal “gaming community” (TMBJ had followed this route, having given up its JO-specific branding over a year prior) to disbanding entirely. None were particularly appealing; we didn’t want PoT to simply disappear, but our leadership was aging; I knew I couldn’t invest the kind of time and effort in revamping PoT that I’d put in back in mid-2004.\nIn short: this was one of the first lessons I learned in walking away. But, in classic “me”, it wasn’t because I came to some incredibly-wise decision to that effect, but because I was slapped in the face with the right decision.\nAt some point, we made the decision to convert to a “gaming community” that had affiliations with multiple games, including JO, but also: Battlefront, StarCraft II, and even Left 4 Dead 2. We had a ranking system set up, and a representative “Senatorial” ambassadorship for each game. The clan seemed on board.\nAnd then simmering egos exploded, and it became clear: we’d made the wrong decision. We quickly changed course, and decided it was time for the venerable PoT experiment to end. In our naive excitement to keep PoT alive, we ignored very real structural problems in the membership that had not been addressed.\n\n\nPostscript\nEven now, I struggle for words to encapsulate everything the Power of Thee taught me, from making my own character skins; configuring and administering dedicated servers; hacking the shit out of Photoshop to make halfway-decent signature graphics; glitching JO in precisely the right way to grab the Flechette launcher through the floor; bunny-hopping; @@@@@@@@@@@@@@@@@@@@-ing.\nBut even more important, and less amenable to precise wording, is the relationships I made and continue to learn from.\n\nKaleb, who I don’t speak to nearly often enough but really taught me everything I know, and even though we disagreed on some things in the end I still have the utmost respect for; he fights for who he loves, and that’s a kind of interpersonal honor that is rare these days\nUnderwhelmed, who selflessly hosted our forums for years, and until I lost touch with him was a kind of unofficial mentor; I hope he’s still rescuing tacos and giving them safe haven in his stomach\nMormi Ganry, a fellow tech guru whose commitment to always doing the right thing was above reproach; of course, this included that amazing instance when he managed to upload Linksys router firmware onto the open admin console for an unsecured D-Link router that belonged to a troll on our server…\nRob, who despite (or because of?) his incessant in-game trash-talking, was one of the most honest and heartfelt individuals I’d ever met\nTahiri, who was my conscience on more than one occasion, and my instructor on many others, and who helped me through relationship issues during my formative years\nJelle, a fiercely loyal friend who I actually visited in Belgium during my 2007 study abroad, and who I also don’t speak to nearly often enough, but who also kept me honest when we disagreed on multiple different fronts\nXixes, who was the quintessential “PoTnah”: always available to help anyone who might need it, always willing to lend a hand, always happy to jump into a clan match even if he knew he wasn’t the right person for the job; he’d give it everything he had\nSwordFish, a Canadian with a wicked hilarious sense of a humor and endless capacity for friendship who I have since sadly lost touch with\nMonkeh, an often-controversial individual who spoke almost exclusively in l33t-sp34k, who didn’t care if he rubbed you the wrong way, and who turned into an exceptional gunner, but whose dedication to PoT and its leadership was never in question\nIain, a quiet and polite member whose unassuming disposition masked a clever wit and incredibly sharp intellect, and especially technical talent, that led us to grant an overdue post-PoT promotion to Jedi Master\n\n…and many, many others: Vader, John, Bill the Pony, IronSlayer, Pablo, Jason, Anakin, Chrury, Deadclown, Rica, Secca, Snarf, Ragnarok, SeparateWays, and plenty others whom I’m forgetting or never knew that well.\nSuffice to say, the clan–really, the people in it–were instrumental in making me into who I am now. I use a lot of the same leadership strategies in my day job, mentoring and instructing new students and training them into researchers; working through personnel conflicts and managing competing egos; and somehow making sure I have time to keep my own skills up to par with the playing field at large. In retrospect, it’s amazing how such an otherwise run-of-the-mill FPS could have had such an outsized impact on me, but I’m eternally grateful for it, and hope only that I can continue to learn from it.\nOnce I find where Tahiri went.\n\n\n\n\n\nCitationBibTeX citation:@online{quinn2018,\n  author = {Shannon Quinn},\n  title = {Jedi {Outcast:} {Echoes} of a Bygone Gaming Era},\n  date = {2018-04-26},\n  url = {https://magsol.github.io/posts/2018-04-26-jedi-outcast-echoes-of-a-bygone-gaming-era/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2018. “Jedi Outcast: Echoes of a Bygone Gaming\nEra.” April 26, 2018. https://magsol.github.io/posts/2018-04-26-jedi-outcast-echoes-of-a-bygone-gaming-era/."
  },
  {
    "objectID": "posts/2023-01-14-year-that-almost-was/index.html",
    "href": "posts/2023-01-14-year-that-almost-was/index.html",
    "title": "2022: A year in review",
    "section": "",
    "text": "Warning\n\n\n\nThere’s going to be language in this post. Consider skipping if you prefer your blog posts merely warmed and with cream; this one is straight out of the pourover.\n\n\n2022 was a fucking shitshow.\nForget the transition out of academia that fell flat on its fucking face in the final mile1. Forget the actual running that went from runway to runway, gunning the engine and building some speed on occasion but without ever quite taking off. Forget 2022’s parting shot of giving our entirely family COVID within days of the year’s end (save our daughter, miraculously and thankfully) when we’ve been so diligent for three fucking years. Forget that we’ve been pretty much the only ones still wearing masks on planes and at our daughter’s daycare, as if “I’ve decided to get on with my life” somehow makes the pandemic over simply by willing it; as if it’s impossible to “get on with life” while also taking basic fucking precautions that hurt no one and help everyone.\nAll of that was rage-inducing beyond words and each deserve their own posts to really break down. But the real story of my 2022 was of burnout that I foolishly thought I could outrun.\n\nBurnout dances to its own tune\nI’ve been burned out for quite awhile now; realistically, there are likely roots going all the way back to graduate school, but things really kicked into gear with the tenure-track position and the stress it brought.\nThe pandemic didn’t create anything new in this regard, but it did act as a force multiplier, frying what little bandwidth I had left and forcing me to confront just how toxic my working circumstances were.\nThis was all complicated by the birth of my daughter, happening at the same time as my promotion and tenure process, wrapped up in some of the most gratuitous displays of academia’s utter disdain both for growing families and, it turns out, straightforward public health guidelines around pandemic mitigation strategies.\nSuffice to say, when I landed a job at Quansight in mid-late 2021, I jumped at the possibility of an exit strategy. Admittedly, I jumped way, way too soon: I was worried of losing the opportunity if I waited (irony), I didn’t have anything approximating a concrete exit strategy from academia (haste), and I thought I could hold down two positions long enough to gracefully exit (fucking LOL).\n\n\nWriting on the wall\nEven when I formalized a sabbatical beginning August 2022–an entire eight months after I started working full-time at Quansight–I was so far beyond any kind of discernible burnout threshold that it’s a miracle I lasted another three months before leaving.\nThrough all of 2022, my burnout was so severe that entire consecutive weeks would go by where I napped daily just to make it through the day. I was besieged by migraine headaches at the base of my neck that radiated down my legs; they wouldn’t respond to ibuprofen, and made literally any activity impossible. By the fall, I was having these migraines 3-4 days a week. But the coup de gr\\(\\hat{a}\\)ce, the real cherry on top of it all was how, on a given work week in 2022, my upper bound for productivity was probably about 25% efficiency.\nYes, I typed that correctly: on a given 40-hour work week, I at my peak could probably crank out about 10 hours of real, actual work. Most of the time, I was operating at some sigma less than that. I’ll take my promotion now.\nThe weirdest thing about this level of burnout probably answers the obvious burning question following that previous revelation: I had no idea this was all related, or that there was even really a problem. The headaches were annoying, the naps made things bearable (in a sense), and surely I was just still getting the hang of things and I’d soon start churning out productive weeks? After all, I just had to hold out until I could sever all ties to academia in… 6-8 more months.\nAbout that.\n\n\n\nMidjourney did a pretty bang-up job when I asked for a tweaked version of “this is fine”.\n\n\nTo address the (one of many, I suspect) elephant in the room: wasn’t I on sabbatical from my academic role? Yes, dear reader, I was. And it was still requiring at least a handful of hours from me, on a good week. Some sabbatical.\nOh yeah, October. Our entire family got RSV in the second half of October. Didn’t I mention that earlier? No? Yeah, that was an entire week where all three of us were sick (so no daycare for kiddo), followed by a second week where my daughter and I developed secondary bacterial infections! Great for the aforementioned productivity!\n\n\nNo options given\nIf there’s anything positive to be said about burnout, it’s this: eventually, it gives you no choice. You reach a point where it’s physically, mentally, emotionally, spiritually, ecumenically, and grammatically impossible to keep moving forward.\nWithout going into detail2, that point came just before Thanksgiving. I left Quansight. I took the entire month of December off. And hooooooly shit y’all, but that month was, honest-to-goodness, maybe the first time in over a year I not only stopped digging the burnout hole deeper, but actually started filling it back in. I can’t describe the feeling of my brain lighting up and making connections and actually functioning–I spun up our household Mastodon instance in that time3! I actually recovered a bit, holy fuck.\nAnd only then did I slowly begin to realize how absolutely fucked I’d been the entire year up until that point. How the fuck did I expect to be able to continue down this road for another six to eight MONTHS?\nIt seems ridiculous–laughable, if it didn’t border so close to outright dangerous–but only in hindsight.\n\n\nLight even in darkness\nMy 2022 was defined by my burnout… but also by my realization of its full extent. And, in doing so, by the start of me turning things around.\nBeyond burnout, there were some other events and accomplishments in 2022 that were cause for celebration by themselves.\nMy wife quit the job that was stifling her and is now pursuing her dreams as a full-time fiction writer. This was one of the very first things I learned about her all those years ago when we met4, and the fact that she’s living it now–and all the challenges and anxieties and freedoms and blessings it comes with–makes me prouder than I’ve been of anyone in years.\nSpeaking of my wife and her writing, she finished a complete draft of the book she’s been working on for the past bit. I finished reading it a week or so ago, and I fucking love it. I may be a little biased, but I also read 30 books last year according to my StoryGraph5, so I have at least an inkling of what I’m talking about. She’s an amazing writer; you should buy it when it’s published!\nMy daughter is rapidly turning into the most fiery and powerful person I could have ever hoped she would be. It’s exhausting and enthralling and I’m so freaking happy to be her dad.\nWe did, in fact, solve some of the flooding problems around our house6. We had extensive work done on the back and front yards, and I can proudly say that our front yard is virtually problem-free and our backyard is… better. Obviously there’s more to be done, but in exchange for a lot of money there was a good amount of progress toward eliminating the literal rivers that swirl around our house during a downpour.\nFor all my breathless pearl-clutching around my running failures, 2022 was, by any reasonable measure, an improvement over 2021, and those improvements should be celebrated… even if they aren’t the impossible gains I wanted.\nStrava has a fitness estimate tracker; it’s obscenely biased in ways I can’t begin to wrap my head around, but it seems like a moderate-to-low variance estimator, so it provides a decent relative intuition on fitness over time. And I have to say: given my 2022, it’s halfway ok.\n\n\n\nYeah, my fitness hasn’t been great the past 6 months, but it’s held relatively steady. Given 2022, that’s an accomplishment by itself.\n\n\nSpeaking of running, my total mileage improved year-over-year. I also ran my first half marathon since before COVID7. It was the slowest half I’ve ever run (by a lot), but I finished. I also ran a handful of other races last year, which helped remind me that racing is a lot of fun–which helped remind me that running is a lot of fun.\n\n\n\nYear-over-year total mileage run. More mileage with fewer runs indicate longer runs.\n\n\nI spun up an entire Mastodon instance, Casa Quinnwitz, on my homelab Raspberry Pi cluster (shout-out to the Mastodon dev team, which is full of super kind and patient folks). It’s pretty much my new socialz home, since Twitter has been rendered all-but-unusable with Tweetbot and all the other third-party clients going belly-up. I kind of love the vibe there; feels very longer-form-proto-Twitter with a pre-Eternal September thing going.\n8\n\n\nWhat’s next?\nI’m back in the academy this semester, teaching my data science practicum course while guiding a half dozen of my remaining students to graduation in May. I have a weekly structure in place that balances my obligations to the academy with my needs for continuing rest, exercise, and my own fun shit. I’m still feeling the after-effects of COVID but am hoping that will taper off as I get back into running again, training for a half marathon in April and multiple shorter races before then. I have a concrete exit strategy from academy, and a timeline of events and milestones to accompany it.\nCrucially, I’ve also adopted a new strategy for handling work-related items coming my way: NO.\nNo, I’m not taking new students.\nNo, I can’t review for your conference/study section/journal.\nNo, I’m not open to new research collaborations.\nNo, I can’t sit on your [insert topic here] panel9.\nNo, I’m not going to be on that committee.\nNo no no no no. No.\nIt’s a really hard fucking thing for a lifetime people-pleaser to set up boundaries, but for me in this moment, it’s both a matter of mere survival as well as a pathway to doing what I really love.\nHere’s to a 2023 of healing. Much love to all of you 🥂\n\n\n\n\n\nFootnotes\n\n\nYes, there will be a future blog post on this. No, I’m not going to expound any further on it here.↩︎\nAsk if you really want to know.↩︎\nDon’t worry, I have an entire series of blog posts (six, I think?) planned to go over it in gross detail. Stay tuned!↩︎\nJust about 17 years ago! 😱 ↩︎\nDitch Goodreads!↩︎\nThis one’s for you, Mom and Dad 🎄✉️ ↩︎\nThe last half I ran was late 2019, almost a 3-year gap!↩︎\nNow I’m just fucking with you. Also I love footnotes, so expect to see a lot of them on every blog post.↩︎\nThough I did get invited to one on ChatGPT, and wow the temptation to say “yes” and then just burn the whole place down is overpowering… I’ll have to think about it.↩︎\n\nCitationBibTeX citation:@online{quinn2023,\n  author = {Shannon Quinn},\n  title = {2022: {A} Year in Review},\n  date = {2023-01-17},\n  url = {https://magsol.github.io/posts/2023-01-14-year-that-almost-was/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2023. “2022: A Year in Review.” January 17,\n2023. https://magsol.github.io/posts/2023-01-14-year-that-almost-was/."
  },
  {
    "objectID": "posts/2023-01-25-mastodon-helm-chart/index.html",
    "href": "posts/2023-01-25-mastodon-helm-chart/index.html",
    "title": "Mastodon, Part II: The Mastodon Helm chart",
    "section": "",
    "text": "This article is part of a series about installing and configuring a Mastodon instance on a cluster of Raspberry Pi computers running k3s. To go back to previous articles in the series, try any of the links below:\n\nIntroduction\nPart I: My home network topology\nPart II: The Mastodon Helm chart (this post)\nPart III: Configuring and installing prerequisites\nPart IV: The waking nightmare that is Let’s Encrypt\nPart V: Actually installing Mastodon\nConclusions\n\nI don’t know about you, dear reader, but when I first started this journey into teaching myself kubernetes, I was elated at the prospect of Helm: a “package manager for kubernetes”, it said! Thank the cloudless heavens; I was getting so bogged down with managing separate yaml files, I was thrilled at the prospect of someone just setting some reasonable defaults and packaging it all together.\n\n\n\nSuch a cruel realization.\n\n\n\nIntroducing the Mastodon chart\nYou can find the latest version of the Mastodon chart here.\nI should mention: when I started working on this in early December, the chart was actually still part of the main Mastodon repo! This meant that changes were much slower to be merged, and as a result I had to implement some workarounds that have since been fixed in the newest chart. Even so, I’ll point out 1) any changes I made, 2) whether those changes still need to be made now, and 3) relevant PRs.\nThe chart repo’s README linked above provides pretty good instructions for getting up and running. Or, in my case, to get some initial error messages that pointed me where I needed to go next.\nAt the bare minimum, everyone has to fill in:\n\nthe whole mastodon.secrets section (four keys)\nthe postgres and redis sections (whether or not they’re enabled in the chart)\nthe mastodon.stmp section for the mailer’s SMTP settings (not technically required, but nobody will be able to register with your instance or reset their passwords without them)\n\nBecause of my circumstances, I also had to modify the elasticsearch section (that’s another bitnami image that wasn’t ARM-compatible, like redis and postgres; but I’m leaving all three of these for the next post!), the ingress section (because I was running traefik instead of the default nginx), and the mastodon.persistence section (because I was using a local NAS for storage–I know, not recommended for production, but for a two-user instance? no problem).\nSo with that lengthy introduction and background out of the way, the salient points here and the primary guiding principles in diving into the chart are:\n\nDisabling the dependencies (elasticsearch, redis, postgres) so I could install them myself later (next post!)\nAdding NAS storage as the primary storage mechanism (I was using nfs subdir external provisioner)\nConfiguring ingress to work with traefik instead of nginx\n\n\n\nThe “easy” stuff: storage and ingress\nProbably the easiest modification to make was the storage. Under mastodon.persistence, there are two main groups: assets and system. They both have their own persistent volumes in case you need to dramatically alter their respective configurations, but I went with the default, adding only one line to each subsection (since storageClassName wasn’t even listed in the default chart, but has templates in the backend that will handle the key-values if provided):\n  persistence:\n    assets:\n      # -- ReadWriteOnce is more widely supported than ReadWriteMany, but limits\n      # scalability, since it requires the Rails and Sidekiq pods to run on the\n      # same node.\n      accessMode: ReadWriteOnce\n      storageClassName: my-nfs-storage-class ### ADDED THIS LINE\n      resources:\n        requests:\n          storage: 10Gi\n    system:\n      accessMode: ReadWriteOnce\n      storageClassName: my-nfs-storage-class ### ADDED THIS LINE\n      resources:\n        requests:\n          storage: 100Gi\nThat’s it! Mischief managed.\nFor ingress, things were a little more complicated. Not because it required more configuration in the chart itself, but because it required more configuration ahead of using the chart at all. The ingress configuration in the Mastodon chart itself masks the hours spent getting traefik set up exactly the way I wanted. Sadly, this is beyond the scope of the Mastodon instance setup (it will definitely appear in a blog post about just getting my k3s cluster off the ground!), but I will discuss configuring the TLS support / SSL certificates in a later post in this series, so stay tuned.\nHere was my configuration (changes from the current default are marked, and comments are deleted for brevity):\ningress:\n  enabled: true\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod-dns\" ### ADDED - will go over in detail in a future post in this series\n  ingressClassName: traefik  ### MODIFIED - added the ingress class name I used\n  hosts:\n    - host: quinnwitz.house  ### MODIFIED - my instance domain name\n      paths:\n        - path: '/'\n  tls:\n    - secretName: mastodon-tls\n      hosts:\n        - quinnwitz.house ### MODIFIED - my instance domain name\nThat’s it! Relatively tame modifications, but belie a groundswell of configuration and wrangling that had already happened. In particular, note the tls.secretName field: I may not have modified it, but I did have to create a Secret named mastodon-tls ahead of deploying the chart! That was part of the magic of cert-manager behind the scenes, communicating with Let’s Encrypt and getting an SSL certificate set up (again, a future post–stay tuned).\n\n\nThe harder stuff: disabling dependencies and modifying templates\nOk, disabling the dependencies was actually easy. Here’s all it took:\n\nGo to redis, postgresql, and elasticsearch sections\nEach one has an enabled: key–set it to false\n\nThat’s it! They’re disabled. Your Helm chart is now fully ARM-compatible!\n…except by disabling all the bitnami charts, you’ve introduced an insidious bug where, for some reason, the Bitnami Common Library chart can no longer be found. Fortunately, the fix is easy.\nGo to the Chart.yaml file and add a new entry under the dependencies: list:\n - name: common\n   version: 1.x.x\n   repository: https://charts.bitnami.com/bitnami\nNow when you run helm dep update before installing the chart, the Common chart will still be downloaded and everything will work, even with the other bitnami dependencies disabled.\nUnfortunately, this leaves us with the trickiest part of the Helm chart modifications: actually tweaking the redis, postgres, and elasticsearch sections (and, in some cases, templates!) to work with the separate instances we’ll spin up later.\nElasticsearch doesn’t require any extra tweaking, so we can leave that alone for now.\nPostgres needs the following fields:\n\npostgresqlHostname: postgres automatically spits this out when you succesfully install it for the first time, so just copy/paste from that\npostgresqlPort: this is almost always 5432, to the point where that’s the default in the helm chart’s backend template\nauth.database, auth.username, and auth.password / auth.postgresPassword are set by you, the user when you install postgres separately; we’ll go over this in the following blog post\nit’s very important to note that auth.password and auth.postgresPassword should have the same value\n\nFinally, redis needs the following fields:\n\nhostname: like postgres, this is spit out automatically when you successfully spin up redis for the first time, so take note of it and copy/paste it here\npassword: this is set by you, the user when you install redis separately; we’ll go over this in the following blog post\nweirdly, I needed to set auth.existingSecret too\n\nTo the last point, I created the following redis-password.yaml file:\napiVersion: v1\nkind: Secret\nmetadata:\n  name: mastodon-redis\n  namespace: mastodon\ntype: Opaque\nstringData:\n  redis-password: <same value as password>\nRunning kubectl apply -f redis-password.yaml into the Mastodon namespace got it working. I still don’t know why I needed both the Secret and the password in the helm chart to get it to work–it may work with just the Secret, or maybe whatever weird situation caused it was fixed and now just the password in the helm chart will work–but this operation was fairly simple and got everything working so I went with it. I created a PR for this a few months back, but it was rolled into a broader PR tasked with migrating the chart over to its own repository, so I’m not sure if its fixes were ever implemented.\nThere were some changes directly to the templates/configmap-env.yaml file that were needed, but thankfully many of these have already been addressed courtesy of some PRs:\n\nFix helm postgresql secret (#19678)\nAllow external redis instance (#6, replaces #20322)\nAdd option to configure external postgresql port (#20370)\nHelm chart improved for ingress (#19826)\n\n\n\nThanks Helm!\nThat about does it for setting up the Helm chart and its corresponding values ahead of installing it… which we won’t actually do for a couple more blog posts yet.\nFor now, I need to rewind a bit to go over 1) how to install the dependencies we just spent an entire blog post disabling and then configuring anyway, and 2) how to get SSL to work.\nOnce we get those items squared away, then we can circle back to the completed Helm chart and install a functioning Mastodon instance! Isn’t being a sysadmin great?!\n\n\n\n\nCitationBibTeX citation:@online{quinn2023,\n  author = {Shannon Quinn},\n  title = {Mastodon, {Part} {II:} {The} {Mastodon} {Helm} Chart},\n  date = {2023-01-25},\n  url = {https://magsol.github.io/2023-01-25-mastodon-helm-chart},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2023. “Mastodon, Part II: The Mastodon Helm\nChart.” January 25, 2023. https://magsol.github.io/2023-01-25-mastodon-helm-chart."
  },
  {
    "objectID": "posts/2023-02-09-configuring-and-installing-prereqs/index.html",
    "href": "posts/2023-02-09-configuring-and-installing-prereqs/index.html",
    "title": "Mastodon, Part III: Configuring and installing the prerequisites",
    "section": "",
    "text": "This article is part of a series about installing and configuring a Mastodon instance on a cluster of Raspberry Pi computers running k3s. To go back to previous articles in the series, try any of the links below:\n\nIntroduction\nPart I: My home network topology\nPart II: The Mastodon Helm chart\nPart III: Configuring and installing prerequisites (this post)\nPart IV: The waking nightmare that is Let’s Encrypt\nPart V: Actually installing Mastodon\nConclusions\n\n\nPreamble\nAs stated previously, the Mastodon image is fully arm64-compatible. However, if and until the dev team chooses to unbundle Mastodon from its dependencies in the Helm chart, we have to worry about multiple applications Mastodon relies on which themselves rely on images that are not arm64-compatible.\nThis isn’t exactly dependency hell, but it did bring to mind a recent blog post by Vicki Boykis–who you should absolutely follow if you don’t already–about how layered modern software engineering and programming have become:\n\nModern software is hard to develop locally, hard to build the internal logic for, and intrinsically hard to deploy, especially so in the case of machine learning. Just take a look at the MLOps paper, which I have nightmares about occasionally.\nThe problem has gotten so bad that you can usually no longer start from scratch and develop and test a single piece of software in a single, preferably local environment.\n\nAs someone in the data science and machine learning space for the past decade+, I can definitely say that this is true. So I hope this post provides some clarity so you can proceed with installing arm64-compatible Mastodon without spending as much time as I did getting it to run.\n\n\nThe short version\nThe upshot is that the three major dependencies of Mastodon–redis, postgres, and elasticsearch–are all bitnami images, and none of bitnami’s images are arm64-compatible.\n(there is a mega-thread open discussing bitnami’s eventual migration to arm64-compatible images, but they’ve made it very clear that it just isn’t a priority for them right now)\nIn mid-November 2022, this issue was posted. I was still working on getting my own Mastodon instance up and running, so it wasn’t until Dec 1 that I was finally able to respond with something concrete (though by no means a complete picture–I still couldn’t figure out what to do about elasticsearch).\nMy response should have some familiar notes from the previous post, specifically regarding the modifications that needed to be made to Chart.yaml.\nAnother user in the issue mentioned the “bitnami-compat” project, which I highly recommend checking out, but which I didn’t end up using, for reasons I’ll get into later in this post.\nThe OP on the issue opened up a Discussion, where I answered with the short version of what this post will contain (along with, again, some content from the last post). You can read that if you like, or continue here! Or both!\nThe key approach I took: rather than swapping out entire charts, I stuck with the bitnami charts referenced in the Mastodon chart, but modified the images each of the bitnami charts referred to. In this way, I could minimize the amount of yaml reconfiguration I was doing to keep things at a reasonable amount of crazy.\n\n\npostgresql\nPostgreSQL was the easiest change, at least if minimizing “number of switches I needed to flip” is our metric of choice here for determining easy versus difficult.\nThe only real change I needed to make was how I performed the helm install process of the bitnami chart for postgres. Here’s the command I used:\nhelm install postgres bitnami/postgresql \\\n    --set global.postgresql.auth.postgresPassword=\"my_postgres_password\" \\\n    --set global.postgresql.auth.username=\"my_postgres_username\" \\\n    --set global.postgresql.auth.password=\"my_postgres_password\" \\\n    --set global.postgresql.auth.database=\"my_postgres_database\" \\\n    --set image.repository=\"postgres\" \\\n    --set image.tag=\"15.0\"\nThat’s it. The only real change of note is the image.repository target: it’s pointing to the official PostgreSQL image on DockerHub, which has arm64-compatible images. The other items related to username, password, and database are items that need to be filled in anyway (here or in the values.yaml file), and the tag just ensures I’m using the same version that the bitnami image would have used, again to minimize any downstream conflicts.\nAnd that was it! I used the bitnami chart with the postgres image, and it worked!\n\n\nredis\nNext up, our in-memory data broker.\nThis process was largely the same as with PostgreSQL, with one notable deviation: I also set the flag to put redis in standalone mode, given that my Pi cluster is resource-constrained and couldn’t afford to have the HA version that, I believe, is the default for the bitnami chart.\nHere’s the helm command:\nhelm install redis bitnami/redis \\\n    --set global.redis.password=\"my_redis_password\" \\\n    --set architecture=\"standalone\" \\\n    --set image.repository=\"redis\" \\\n    --set image.tag=\"7.0\"\nAgain, the password is something we need to set up anyway, the architecture is set to standalone to minimize its in-memory footprint, tag is meant to match with the bitnami version, and finally the image.repository points to the official redis image on DockerHub which, like PostgreSQL, has an arm64-compatible version.\n\n\nelasticsearch OpenSearch\nI tried to get elasticsearch to work. I really did.\nI started off the same way as with postgres and redis: like the first two, there are only a few critical global parameters that need to be set, and they’re the usual suspects–change the image registry to point to the official image on DockerHub, change the image tag to match the bitnami image version, and… that’s really about it.\nThe hang-ups, crashes, and reboots started immediately. Turns out, elasticsearch is incredibly resource-intensive. So I set about trying to set absolutely minimal overheads: setting master and data replicas to 1, constraining the java heap size, and disabling ingest… none of which worked.\nEven aside from the resource constraints, there was a second problem. For whatever reason, the bitnami chart for elasticsearch has a second container–the “kernel settings modifier”–that is part of the pod, and which also has an image that, by default, is not compatible with ARM. So in theory, to get elasticsearch to work with the same technique, the following fields would also have to be changed in the helm chart:\n    --set sysctlImage.registry=\"ghcr.io\" \\\n    --set sysctlImage.repository=\"zcube/bitnami-compat/bitnami-shell\" \\\n    --set sysctlImage.tag=\"11.0.0-debian-11-r39\" \\\nThis is a bit different from the changes made with postgres and redis. There is no “official” distribution of the “kernel settings modifier” image, as this is exclusive to bitnami. Instead, we needed to go to the bitnami-compat project which is attempting to make bitnami-compatible arm64 images for all the major charts, and which could feasibly serve as drop-in replacements for redis and postgres as well (I just didn’t try them because I got them working before discovering bitnami-compat). But it’s perfect for this situation.\nSuffice to say, this completely solved the architectural compatibility issues, but I still could not fix the resourcing problems without fundamentally hobbling elasticsearch to the point of futility.\nInstead, I followed some advice from the Mastodon devs who have, unofficially, been able to get OpenSearch to work as a drop-in elasticsearch replacement in Mastodon.\n(Side note: OpenSearch is based on Apache Lucene, which was the progenitor project to Apache Mahout, for which I’m a member of its PMC! Small world. I love open source <3 )\nTurns out, OpenSearch is remarkable, both in its minimal resource usage and with its ease of dropping right in where elasticsearch would go. My only complaint was the chart’s use of a multi-line yaml string in its settings, which–to my limited knowledge and experience, at least–precluded its exclusive command-line use, and forced me instead to modify the values.yaml and pass that directly to helm. Still, there were very few modifications I needed to make–here’s an indicator with line numbers corresponding to what is currently the latest version of the chart (committed Jan 3, 2023):\n# Line 8: again, needed to keep things minimal\nsingleNode: true\n\n# Line 22: just to be obnoxiously consistent\nreplicas: 1\n\n# config.opensearch.yml | plugins.security\n# Insert the following line just below Line 61\n# *** This might be the single most important change! ***\ndisabled: true\n\n# Added somewhere under persistence, after Line 187\nstorageClass: <my storage class>\n\n# Line 299\nsecurityConfig.enabled: false\nThat’s all I needed. Then by passing the edited values.yaml to helm install, it ran just fine.\n\n\nPostamble\nThat’s it for the prerequisites! At this point, you could pretty much spin up a Mastodon instance as configured. However, before getting to how I went about that process, I wanted to touch on one final problem I ran into, which–despite the nit-picky-ness of getting these arm64-compatible dependencies working–is where I actually spent most of my time trying to get Mastodon up and running: obtaining an SSL certificate through Let’s Encrypt.\nUntil next time!\n\n\n\n\nCitationBibTeX citation:@online{quinn2023,\n  author = {Shannon Quinn},\n  title = {Mastodon, {Part} {III:} {Configuring} and Installing the\n    Prerequisites},\n  date = {2023-02-09},\n  url = {https://magsol.github.io/2023-02-09-configuring-and-installing-prereqs},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2023. “Mastodon, Part III: Configuring and\nInstalling the Prerequisites.” February 9, 2023. https://magsol.github.io/2023-02-09-configuring-and-installing-prereqs."
  },
  {
    "objectID": "posts/2022-12-13-pardon-the-dust/index.html",
    "href": "posts/2022-12-13-pardon-the-dust/index.html",
    "title": "Pardon de dust (2)",
    "section": "",
    "text": "Why hello there. You may have noticed that things look a little bit different around here.\nI’m in the process of migrating my blog off Pelican and on to Quarto.\nWhy, you ask? Honestly, I got tired of having to fix a broken plugin or failed git push every. single. time. that I finished writing out a blog post. It gave an already-infrequent task an even higher activation threshold, and during a stretch where spare bandwidth was an incredible luxury.\nIn short: I’d really like to blog more often, and from what I’ve seen, Quarto will help me do just that. It definitely requires some extra bandwidth to get things migrated over, but fortunately: I have some of that at the moment :)\nStay tuned! In the meantime, please enjoy the above recent photo of Clover helping us put up our tree.\n\n\n\nCitationBibTeX citation:@online{quinn2022,\n  author = {Shannon Quinn},\n  title = {Pardon de Dust (2)},\n  date = {2022-12-13},\n  url = {https://magsol.github.io/posts/2022-12-13-pardon-the-dust/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2022. “Pardon de Dust (2).” December 13,\n2022. https://magsol.github.io/posts/2022-12-13-pardon-the-dust/."
  },
  {
    "objectID": "posts/2023-02-15-calibrating-a-wildlife-camera/index.html",
    "href": "posts/2023-02-15-calibrating-a-wildlife-camera/index.html",
    "title": "Setting up a wildlife camera",
    "section": "",
    "text": "For years, I’ve been wanting to set up an outdoor wildlife camera. Somewhere in the PyImageSearch forums1 there’s a post from 2017-me remarking on how excited I am to have finally gotten my hands on an Nvidia 1080 Ti and, therefore, sufficient horsepower to chew up streaming video from outdoors.\nIn case some readers are unaware: Athens is a quintessential college town where, even if starting from the middle of downtown, you’re only ever at most 15 minutes from literal cow pastures. As such, encounters with wildlife are frequent and to be expected if you’re spending any decent amount of time here.\n\nIt’s always the year of the rabbit\nThere was a stretch of time, also back around 2017 I think, where our bunny Clover would occasionally2 wake us up in the middle of the night by thumping. Again, for those who may not know, rabbits will thump if they sense danger as a way of warning those around them. Clover in particular is also known to thump when she’s having fun, but these few times when we woke up and checked, she was doing her best statue imitation in between thumps, strongly suggesting she really was scared of… something.\nWe never figured out what, exactly. Best guess: her super-sensitive rabbit ears + eyes picked up something prowling outside in the dark that our duller human senses just couldn’t perceive. Which also gave me a specific application for night cameras beyond simple curiosity: to try and figure out what, if anything, was making Clover nervous (I even had an idea to include some kind of seismometer so I could sync up the offline video analysis with Clover’s thumps, but it’s been years since she last woke us up with thumping so I figure I missed the moment).\n\n\nI normally like deer\nBut I was still curious about the nearby wildlife. This only intensified in the summer of 2021: unusually ravenous deer3 ate all the lilies in our front yard before they even bloomed. An idea formed to sync a night camera up with a programmable drone that could, after identifying the deer in the yard, harass them away from the lilies. Oddly, summer 2022 was a return to normal: only one flower was eaten early on in the season; the other few dozen went through their full lifecycle, never getting eaten.\nBut even so, I still wanted to see what was cruising around our neighborhood.\n\n\nBring on the over-engineered solution\nYes, dear reader–years have passed in this retelling with little to no progress on the wildlife front. I will readily admit this project suffered what most personal projects do. I will say this, though: in my defense, 2018 through 2021 was the back half of my tenure-track appointment. Couple that with welcoming my daughter, and the onset of a global pandemic… yeah. A liiiiittle bit of burnout4, plus a LOT of higher-priority items to worry about than a wildlife camera for the sake of curiosity.\nBut by summer 2022, I finally had something physically taking shape–head over to my July 2022 blog post to check it out, complete with photos! I even mounted the birdhouse outside, calibrated the camera’s field of view, and wired it all up… but then left it for several more months.\nNow I’m finally getting some hard, empirical data on how it’s all working. And man, it’s going to be a challenge to have this work well.\n\n\nTechnical challenges\nLegion.\nBy far the biggest challenge I’m dealing with is how resource-constrained the Raspberry Pi 3B+ is. I’m working with 1GB of RAM, though the effective memory available at any given moment is maaaybe 75% of that; as such, 66% is the safe margin I operate with. Another limitation is the SD card size (effectively the hard drive of the Pi): at least when I purchased it, the limit was 32GB. That’s now no longer the case, but I haven’t gotten around to reformatting it, so it’s still a 32GB limit for now.\nThis effectively means that capturing lots of video for testing purposes is difficult. Even reasonable resolutions like 1280x720 at 30fps will exhaust the little Pi’s memory after a mere 4 minutes of video capture, assuming all the buffering was happening in RAM.\nI looked into streaming the video directly as it’s captured; that was, after all, the idea I had behind purchasing the 1080 Ti back in 2017. However, the 3B+ wifi operates only on the 2.4GHz band, which… is unfortunately shared by our baby monitor. Thus, whenever the Pi is transferring data over the air, the baby monitor becomes completely unusable.\nSo the upshot here is\n\nI need to dramatically downsample the incoming video feed, and\nany real-time processing I want to do (including downsampling) has to be done on the Pi itself\n\nI have been looking into things like power-over-ethernet to try and solve #2 (though it would require running an ethernet cable outside, which has its own challenges), and I’ve been running some experiments on the most effective downsampling methods for #1. I’ve also been strongly considering simply upgrading the Pi to a 4B when they become available again, as they can operate on the 5GHz wifi band, and can go up to 8GB of memory. Together, these two immediate fixes would dramatically simplify the situation. But Pi 4s most likely won’t be readily available again until Q2 this year (a few months from now, at least).\n\n\nLogistical challenges\nThere are a ton of unknowns when it comes to what kind of data I can expect. Already the few experiments I’ve run have shown a wide variability in the video I capture in the context of trying to decide on-the-fly what to keep and what to discard.\nThe Picamera2 library also recently entered “beta” (from “alpha”). While that’s most certainly a positive development, it still means the library is undergoing substantial changes, and so not only may functionality change very suddenly, but–as I’ve already been encountering–existing functionality is often poorly documented, if at all. It took me some time to piece together how to configure both high-res and low-res video streams to capture the full field of view of the camera (relative to the camera’s native resolution), rather than cropping out a section, as is what would happen with most of the configurations in the examples folder.\nOh, yeah: I also have a full-time job, and a toddler. So those are definitely logistics to be considered.\n\n\nExperiments\nI have run a few experiments to get a feel for what to expect. The latest commit (as of writing this post) shows what the experiments more or less look like. Here are the highlights:\n\nA dual-stream video recording configuration, where the high-res is set to 1640x1232 and the low-res is 410x308.\nThe camera runs for a fixed period of time (in the script, it’s 8 hours).\nDuring that time, a continuous loop does the following:\n\nGrab a frame from the low-res stream.\nConvert this frame from YUV to grayscale (Picamera2 requires low-res feeds to be in YUV; fortunately, this step doesn’t seem too arduous).\nCompare this frame to the previous frame by way of calculating mean squared error (MSE). This provides some measure of how much has changed from one sequential frame to the next.\nIf MSE exceeds some threshold, start recording a video with the high-res stream. Continue recording so long as MSE exceeds that threshold.\nIf MSE drops below that threshold and stays there for a certain length of time, stop the high-res stream.\nHang onto all MSE measurements.\n\n\nThat’s the basic gist. It’s functional, if blunt. Fortunately, I’ve already collected some interesting data. For instance, here’s an MSE plot from one 8-hour experiment I ran. Important to note: these MSE measurements are only from the events that exceeded the MSE threshold (I’m running separate experiments to try and determine what a baseline MSE looks like).\n\nOne’s first reaction to this plot might be “Huh, there’s a wide variability in the things that can trigger MSE to exceed the threshold!”. And that would most certainly be correct. But even more complicating is the fact ALL of these events are of the same thing: a car driving by on the street. Not only is it not really something I’m interested in–it’s a wildlife camera, after all–but clearly MSE is ill-suited as a method for identifying the kind of event behind it.\nI ran a second experiment over 10 minutes to investigate what MSE baselines might look like (and I’m currently running a longer one; results TBD), but basically you have something that looks like this:\n\nMy take-away from this plot is: given the 30fps capture rate (or very close to it; at least, depending on how much real-time processing I try to cram in), very little changes from one frame to the next. Empirically, it’s a little more than a single pixel. However, there’s a lot this plot doesn’t tell me, such as:\n\nWhat are the effects of weather, such as wind or rain, on the baseline MSE? (not a clue)\nHow does absolute MSE change with respect to resolution, fps, or other camera settings? (in theory, MSE should scale with resolution; fps could at least be simulated by systematically downsampling, though upsampling would be more difficult)\nWhat are the effects of night vs day on MSE? (again, in theory this shouldn’t be a huge deal, as I only plan to operate the camera at night)\nHow can MSE identify two separate events vs something like a person who stands still long enough to make it seem like two separate events? (it probably can’t)\n\nAnyway, I’m running a 24-hour test right now that will hopefully provide at least a little more intuition into the role of MSE vs the real world, if not any outright answers to the above questions.\nFinally, I did want to get some feel for the overall performance of the code itself. I wanted to try and understand what I was working with in terms of options for real-time processing. So I ran a profiler on the same 10-minute experiment I ran above, and this is what came back:\n\nThis was comforting to see, as I had been worried the real-time conversion of YUV to grayscale may have been a bigger performance hit; turns out, it’s over two orders of magnitude less problematic than Picamera2 internals, and an order of magnitude less so than the numpy.mean function call for calculating MSE (and this is something I might be able to optimize a bit with some clever leveraging of in-memory data structures).\nI was even able to look at the timestamping of the MSE calculations themselves to see that, by far, I was very close to the 30fps sampling rate of the camera itself, meaning I definitely have some head room for additional real-time operations. Granted, this concern has always been secondary to memory constraints, but still: it’s good to know where the hard limits are, and where we have some room to operate.\n\n\nOngoing\nIt’s clear that, if there are animals prowling around at night, they don’t elicit much of a reaction from MSE, meaning I’m going to need smarter methods of teasing them out. One thought I had was considering both MSE magnitude and duration, but for that I’d need a much more thorough understanding of the role of the baseline MSE (hence the 24-hour experiment). Another thought I had was combining this with a window of frames, rather than just instantaneous MSE over a pair of frames. Finally, I also wanted to look into some basic (non-DL) object detection in OpenCV, since considering first-order image features like edges and corners might be more sensitive to small animals walking around while also keeping added computationl and memory demands at a minimum.\nStay tuned!\n\n\n\n\n\nFootnotes\n\n\nRIP.↩︎\nEvery few months, so not very often. The impressive bit here is that a 4.5lb rabbit could wake up two snoring humans through multiple walls and a closed door.↩︎\nWe assume. We didn’t have the camera in place to confirm, but we did hear numerous anecdotes from folks also suggesting the deer were weirdly ravenous and less fearful of humans that year.↩︎\nHopefully obvious understatement.↩︎\n\nCitationBibTeX citation:@online{quinn2023,\n  author = {Shannon Quinn},\n  title = {Setting up a Wildlife Camera},\n  date = {2023-02-15},\n  url = {https://magsol.github.io/2023-02-15-calibrating-a-wildlife-camera},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2023. “Setting up a Wildlife Camera.”\nFebruary 15, 2023. https://magsol.github.io/2023-02-15-calibrating-a-wildlife-camera."
  },
  {
    "objectID": "posts/2019-06-03-quinnwitz-in-ireland/index.html",
    "href": "posts/2019-06-03-quinnwitz-in-ireland/index.html",
    "title": "Quinnwitz in Ireland",
    "section": "",
    "text": "The Lady and I just returned from a 12-day trip to Ireland (with a stop at the very start in Kent, England, to visit some dear friends and their 6-month old twins!).\nI can’t begin to describe how incredible the trip was. It was one of those dreams you realize at some point you’ve been discussing with your significant other for years–quips here and there about “wouldn’t it be awesome to visit x” or “when we visit y someday…”. Ireland had been at the top of our list of international locations to see since years before we even got married, but it was always 5-10 years in the future, and never got any closer to reality.\nUntil that dear friend’s wedding in Bedford, England, in late summer 2017. At some point during some downtime in that long weekend, Ireland came up again in the same way it always did, but whether it was the international setting we were already in or some other twist of fate, The Lady suddenly said: “Let’s set a date.”\nThat day in August 2017, we set a tentative, but actual, date of May 2019. And we nailed it.\n\nOverview\nThe logistics of the trip were pretty complicated. First, we wanted to fly into London and spend a day visiting those friends of ours out in Kent. Next, we wanted to start our journey in Ireland by spending a few days in Dublin.\nFrom there, we wanted to hike in Wicklow National Park before spending a few days in Killarney, exploring the Ring of Kerry (important note: not a “ring” as in a piece of jewelry).\nFinally, we wanted to drive to Galway and spend a few days there, before returning to Dublin and flying back home.\ntl;dr A travel agent will make your life a lot easier when your international travels have a lot of moving parts.\n\n\nThe Emerald Isle\nThe country was seriously amazing. Ireland is the most incredible combination of different landscapes and ecosystems all coexisting side by side; driving from Dublin to Killarney to Galway and back will show multiple distinct countrysides that change seamlessly yet suddenly.\nWithout further adieu, I’ll post some of my favorite pictures here from the trip.\n\nIn front of the Oscar Wilde statue in Dublin.\n\nThe Guinness Storehouse in Dublin.\n\nIn the Book of Kells exhibit at Trinity College in Dublin.\n\nAt Wicklow park, before a 9-mile hike.\n\nAlso Wicklow park, about halfway through the hike.\n\nRunning the Gap of Dunloe in Killarney.\n \nThe Lady and myself running in the Gap.\n\nThe Lady meets an adorable Irish wolfhound during our Ring of Kerry tour.\n\nCoastline stop along the Ring of Kerry tour.\n\nWe met a very friendly regular at the Secret Garden in Galway.\n\nSitting in the main square at Galway.\n\n\n\n\nCitationBibTeX citation:@online{quinn2019,\n  author = {Shannon Quinn},\n  title = {Quinnwitz in {Ireland}},\n  date = {2019-06-03},\n  url = {https://magsol.github.io/2019-06-03-quinnwitz-in-ireland},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2019. “Quinnwitz in Ireland.” June 3, 2019.\nhttps://magsol.github.io/2019-06-03-quinnwitz-in-ireland."
  },
  {
    "objectID": "posts/2016-02-02-nsf-crii-reviewer-feedback/index.html",
    "href": "posts/2016-02-02-nsf-crii-reviewer-feedback/index.html",
    "title": "Reviewing a reviewed grant’s reviews",
    "section": "",
    "text": "Rejection in any context sucks. As a new faculty trying to prove himself (to himself, but most importantly, to his tenure committee), I particularly hate rejections in the context of grant proposals and paper submissions. The “nice” thing about the latter rejection is that it’s marginally easier to resubmit a manuscript elsewhere; there are more journals and conferences than ever, especially in computer science.\nLast September, I submitted a proposal in line with NSF’s 15-569 program solicitation: the Research Initiation Initiative in Computer and Information Science and Engineering.\nInsert jokes involving “initiation initiative” imagery here (sorry, I don’t have an avalanche of Advil).\nSomewhat unsurprisingly but nonetheless disappointingly, I received notification today that the proposal was rejected. I say unsurprising because the proposal itself was incredibly rushed; we hit “submit” about two minutes before deadline. It was my first major grant proposal, so there were bound to be some mishaps.\nSo: let’s get into the reviewer feedback!"
  },
  {
    "objectID": "posts/2016-02-02-nsf-crii-reviewer-feedback/index.html#conclusions",
    "href": "posts/2016-02-02-nsf-crii-reviewer-feedback/index.html#conclusions",
    "title": "Reviewing a reviewed grant’s reviews",
    "section": "Conclusions",
    "text": "Conclusions\nFor the vast majority of weaknesses, their immediate impetus can be summed up thusly: I started writing the grant the day before deadline. That’s a no-no, and contributed directly to the panicked flurry at the end and lack of detail in the proposal itself. Starting earlier will solve these problems.\nThe last point that genuinely concerns me, though, is the first reviewer’s comment on differentiating myself from my graduate advisors. It’s true that this proposal took work I started as a graduate student, and I agree that it’s important to build an independent research group such that I don’t have to rely on my graduate advisors for funding.\nBut I suppose I could boil this down to time constraints as well: given more elbow room, I could have provided a more detailed development plan that clearly differentiated itself from work done before. Rather than relying on the “we propose to extend…” mantra, I could have delved into much greater detail on the methods I’d wanted to use and why their application would be novel.\nSo there you have it: a review of grant reviews. Nothing left to do here but incorporate the feedback and push out more effective proposals in the months to come!"
  },
  {
    "objectID": "posts/2023-01-23-mastodon-home-network-topology/index.html",
    "href": "posts/2023-01-23-mastodon-home-network-topology/index.html",
    "title": "Mastodon, Part I: My home network topology",
    "section": "",
    "text": "This article is part of a series about installing and configuring a Mastodon instance on a cluster of Raspberry Pi computers running k3s. To go back to previous articles in the series, try any of the links below:\n\nIntroduction\nPart I: My home network topology (this post)\nPart II: The Mastodon Helm chart\nPart III: Configuring and installing prerequisites\nPart IV: The waking nightmare that is Let’s Encrypt\nPart V: Actually installing Mastodon\nConclusions\n\nAdmittedly, this post in the series will be less “here’s how to spin up your own instance” than “here’s why I had so many problems that are specific just to me”, so if you have a solid handle on your own home network topology and/or are a DNS savant, feel free to skip this post.\nFor the rest of us mere networking mortals, let me walk you through a network hiccup that has been stymieing my attempt at an honest-to-goodness homelab kubernetes cluster for the better part of the last couple years.\n\nThanks a lot, Bezos\nDuring the height of the pandemic in summer 2020–and somewhat in preparation for the birth of our daughter–I performed some long-overdue home network upgrades. This included 1) switching over to fiber internet, and 2) upgrading to a mesh network, rather than the janky router-plus-extender setup that honestly never really worked all that well. The router itself was already 5+ years old (purchased when we first moved into the house), so it needed an upgrade anyway.\nAt the recommendation of some friends, I went with eero. Honestly, I’d still recommend it: it’s been rock-solid, with no problems between my Apple devices (MBP, iPad Pro, and iPhone), my wife’s Android+Windows devices (Surface, Pixels), and our myriad internet-of-sh!t devices strewn throughout the house. Literally zero problems, which I honestly can’t even say for our old router.\n…with, I suppose, one exception: putting the eeros into bridge mode.\n\n\nBridge mode is not what you think it is\nAs far as I’m aware, across all devices–from ISP modems to VirtualBox to Docker to home routers–the term “bridge mode” has a common intuition: it means the device that has been placed into bridge mode relinquishes any intelligent packet organizing methods it may have been using before and simply acts as a simple “bridge” between whatever entities it is connected to. As such, it doesn’t really care what those entities are, it just passes traffic between them.\nNot so with eeros.\nTo illustrate, here is what my home network looked like before starting any of this craziness.\n\n\n\nWhy yes, I did configure MoCA for my home mesh, thanks for asking.\n\n\nThis setup worked, except… see that Raspberry Pi cluster in the bottom left? That’s where I installed k3s for tinkering, but “tinkering” is pretty much all anything amounted to, because eeros have an odd limitation when it comes to port forwarding: they don’t allow IP-based service forwarding, or at least, service forwarding that is based solely on IP addresses; they also require MAC addresses. When dealing with ephemeral services created by kubernetes clusters on floating IP ranges, there aren’t associated MAC addresses with these services, which makes it impossible to use software-based load balancers like metallb, and therefore impossible to deploy multiple services that use similar configurations–like, say, multiple websites: Mastodon and something else.\nSo the first thing I had to do, were I to run my own instance, was to figure out a network configuration that would allow me to do IP-based port forwarding. I recalled that my old router had this ability, so I figured: let’s just pull that out of retirement and use it purely for port forwarding!\nFollowing was my first attempt. Note the major changes: the router has taken the place of the “main” eero as connecting directly to the ISP modem, and what was formerly the “main” eero is now just a wireless access point, connected to nothing except the router.\n\n\n\nMy first attempt at putting the eeros in bridge mode and un-retiring my old router.\n\n\nSuffice to say, this didn’t work. I mean, it kind of worked: the Raspberry Pi cluster was getting the right traffic forwarded to it. But seemingly random devices on the network would, suddenly and for no reason I could discern, disconnect and refuse to reconnect unless the entire network was rebooted.\nNot exactly a tenable situation. So I reverted to the previous configuration where the eeros were in charge while I tried to figure out what was going on.\nFast forward about 8 months. I finally, finally found this post on Reddit (because why would eero have it in their technical support documents?) from a couple years ago, with this critical element:\n\nApparently, even in bridge mode, there has to be at least one eero that can “see” the entirety of your home network (i.e., all incoming traffic should pass through it).\nThis… made absolutely no sense to me, as it directly contravened my understanding of “bridge mode”. But I went with it, and retooled my network to follow this new bit of information.\nHere was my next attempt. Like my previous attempt, the router is connected directly to the ISP model. However, unlike my previous attempt, what was the “main” eero in the original configuration–while still connected to the router–now sits between the router and the entire rest of the home network, rather than just the router and… whatever devices deign to connect wirelessly to it.\n\n\n\nMy final attempt at a network reconfiguration, this time putting one eero ahead of the rest of the home network.\n\n\nThis configuration, while still strange to me, officially works–or at least, it’s worked for the past few months with no issues.\n\n\nLoad balancers: green\nWith the issue of the k3s Raspberry Pi cluster being able to receive incoming traffic from the wider internet effectively resolved, I could now undertake the process of installing a Mastodon instance on the cluster with gusto.\nIn the next post, we’ll look at the Mastodon Helm chart in all its glory. Stay tuned!\n\n\n\n\nCitationBibTeX citation:@online{quinn2023,\n  author = {Shannon Quinn},\n  title = {Mastodon, {Part} {I:} {My} Home Network Topology},\n  date = {2023-01-23},\n  url = {https://magsol.github.io/posts/2023-01-23-mastodon-home-network-topology/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2023. “Mastodon, Part I: My Home Network\nTopology.” January 23, 2023. https://magsol.github.io/posts/2023-01-23-mastodon-home-network-topology/."
  },
  {
    "objectID": "posts/2023-01-20-mastodon-instance-k3s-rpi-introduction/index.html",
    "href": "posts/2023-01-20-mastodon-instance-k3s-rpi-introduction/index.html",
    "title": "Running your own Mastodon instance on a Raspberry Pi k3s cluster",
    "section": "",
    "text": "Introduction (this post)\nPart I: My home network topology\nPart II: The Mastodon Helm chart\nPart III: Configuring and installing prerequisites\nPart IV: The waking nightmare that is Let’s Encrypt\nPart V: Actually installing Mastodon\nConclusions\n\nAs I mentioned in my previous post, I spent the last month of last year spinning up my own Mastodon instance (which you can check out!) I’ve had a Raspberry Pi cluster of 5x Pi 4B modules sitting around for the better part of the last two years1. I’ve occasionally toyed with installing k3s and experimenting with various bits and pieces of kubernetes, but never actually deployed something I found useful.\n\n\n\nDon’t worry, they’re well protected.\n\n\nDon’t get me wrong–I do want to go over how I installed and configured k3s on my Raspberry Pi cluster. It’s remarkable how quickly this area of things moves, and the guides I was working off for this were all 2-3 years old, and remarkably outdated. So a more recent tutorial on that basic component would definitely have its niche, I think.\nBut first, I want to kick off a series of posts detailing how I got a Mastodon instance running! It took a surprising amount of wrangling, so I wanted to share my experience before I forget the tiny details.\nWhy would you be interested in this series? Aside from the usual rough-and-tumble of installing anything on kubernetes via helm, the two parts that took the greatest amount of time and effort were 1) getting the Mastodon dependencies to work, and 2) wrestling Let’s Encrypt into submission. That first point is interesting because while Mastodon itself works just fine on ARM, the default images included in the Mastodon helm chart for the dependencies do NOT, and so it won’t work out-of-the-box on a Raspberry Pi cluster. And the second point was just plain rage-inducing, and I’d love for folks to not have to experience that.\nI’ll fill in the links as I write the posts, so that you can bookmark this page if you’d like, though I’ll make sure to include the links on the other posts as well as I write them. In the meantime, don’t hesitate to drop any pointers / corrections / questions!\n\n\n\n\nFootnotes\n\n\nYes, I did indeed purchase them two years ago. Would’ve been nigh impossible to get them at any time in between 😬↩︎\n\nCitationBibTeX citation:@online{quinn2023,\n  author = {Shannon Quinn},\n  title = {Running Your Own {Mastodon} Instance on a {Raspberry} {Pi}\n    K3s Cluster},\n  date = {2023-01-20},\n  url = {https://magsol.github.io/posts/2023-01-20-mastodon-instance-k3s-rpi-introduction/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2023. “Running Your Own Mastodon Instance on a\nRaspberry Pi K3s Cluster.” January 20, 2023. https://magsol.github.io/posts/2023-01-20-mastodon-instance-k3s-rpi-introduction/."
  },
  {
    "objectID": "posts/2019-08-12-breath-of-the-wild/index.html",
    "href": "posts/2019-08-12-breath-of-the-wild/index.html",
    "title": "Breath of Fresh (albeit, indoor) Air",
    "section": "",
    "text": "This is a divergence that is simultaneously strange and entirely predictable.\nAllow me to explain.\nFirst and foremost, I’ve been training for my first marathon in 4.5 years for the past several months. It’s largely consisted of base-building, but in the last couple of weeks we entered the “official” 16-week marathon training period…\n…and my knee started pulling. Oh! And it coincided with the first week of decent summer weather we’ve had here in Athens since…2018? And if the past two weeks are any indication, this summer is going to be as bad as that brutal one in 2016.\n\nAnyway!\nSince I noticed the pulling in my knee the week before “official” training was to begin, my coach and I agreed–in the name of being super-cautious this early in the training cycle–that I would take a week off from running, focus on cross-training and physical therapy exercises, and let my knee heal up. During this time, I dove into the 2017 hit Zelda: Breath of the Wild, the new Zelda release for the Nintendo Switch, and logged–to use the technical term–a shitton of hours.\n\nLet me back up a little further.\nI’ve never been secretive about my love of video gaming (and board gaming, and regular old sportsball gaming… any kind of gaming, really). But my real passion in video games has largely been constrained to variants of first-person shooters and real-time strategy. This includes the usual suspects like Left 4 Dead 2 and StarCraft II, but also slight variations like Civilization V (haven’t gotten the hang of VI yet), Cities: Skylines, Homeworld, and Sins of a Solar Empire.\nThe upshot: Zelda has never really been on my radar.\nI mean, of course I’m familiar with the Zelda franchise. Back in the days of the OG GameBoy, I played Link’s Awakening. A lot of it. I played through it so many times I eventually figured out how to find enough “secret seashells” to get the Master Sword just before completing the 4th of the 8 main dungeons.\n\n(if it’s possible to get the sword sooner than that, don’t bother, I don’t want to know)\nBut for those who know the larger Zelda lore, this installment exists awkwardly both within but also without the Zelda story. I mean–SPOILERS for a 20+ year old game SPOILERS–it was all a dream. Or was it instead a reality that existed within our own, but vanished when the Wind Fish woke up? Who knows?\n\n(apparently there was a Nintendo Switch remake of Link’s Awakening?)\nRegardless, while the usual Zelda themes certainly exist in Link’s Awakening, the specific story points don’t. So years later it was a shock to learn that Link actually had a primary antagonist, Ganon.\nWhen I first met my future wife, one of the many things about her that charmed me was her love of the Zelda franchise, especially Ocarina of Time. I was never super motivated to play the games myself, but something that seems almost uniquely exclusive to Zelda games: they’re incredibly fun to watch someone else play! Even better, The Lady and I soon discovered that, not only did we have different playstyles when it came to video games, but they complemented each other in a way that really helped her/us solve the puzzles in these games with ruthless efficiency.\nBut even after watching her crush Ganon in Ocarina of Time, Twilight Princess, and Ganon’s progenitor in Skyward Sword (which I bought her as a gift on the very first Nintendo console we ever owned together… awwwwwww), I still never felt the itch to play the game myself.\nAnd when I likewise bought Breath of the Wild, again for her to play, I once more assumed I’d watch, point things out here and there, and let her Zelda fandom run wild. Plus, I’d seen the reviews of this installment, and knew that while they’d thrown out a lot of “typical” Zelda grind, they also added a bunch of new gaming mechanisms that, on the surface, I held my nose for:\n\nBreakable weapons: I’d played games where weapons only lasted for finite amounts of time, and holy shit did this mechanic annoy the crap out of me.\nRecipes: I haven’t actually played a game with this mechanic, but it’s been showing up more frequently in RPGs, a gaming genre I generally have a very, very hard time getting into.\nSeasonality: This encompasses not only night/day changes, but also changes in weather patterns in-game, and subsequent changes in clothing / preparation of countermeasures (food, elixirs) in order to survive. I’ve played a lot of games with the night/day mechanic and have found it “meh” at best, super f*ckin annoying at worst. Combined with the need to constantly swap out clothing to adjust (and potentially lose abilities the previous clothing gave me) was irksome just to think about.\nNonlinear open world: Again, nothing against nonlinear gameplay–I for one love that Civilization has multiple win conditions, and that the StarCraft II missions are built to discourage “turtling” and force you to get creative–but as an avid follower of Zero Punctuation I know how “well” Ubisoft’s (for example) “nonlinear” “open world” games have faired, and for the life of me I couldn’t see a game on Zelda’s scope doing any better.\n\nBoy oh boy, was I wrong.\n\nI watched The Lady play a game of her own for quite awhile, and at some point just kinda thought: eh, why not? and started my own game.\nI was hooked. I can’t even explain why; even while writing that list of grievances, I kept thinking of examples other than Breath of the Wild with those mechanics and getting annoyed all over again. And yet, these are so well-done in Breath of the Wild that I don’t even notice them. Even moreso, annoyances in previous Zelda iterations–the “forced save points” of Skyward Sword, the nails-on-a-chalkboard running-back-and-forth over the Ocarina landscape to finish a simple side quest, the rupee limitations of literally every other Zelda game (until you bought a bigger rupee purse ???), the constant hunt for more arrows, and the lack of any jumping ability–they’re all gone!\nThe best thing I can say about this game is that they did an incredible job of 1) identifying the annoying things of previous Zelda games and cutting them out, and 2) introducing these new mechanics in a way that felt natural and intuitive. That’s really the crux of it: the game is easy to figure out, even while the actual gameplay is incredibly, brutally, and satisfyingly challenging.\nThat mastery of basics is why the game scales to such a massive landscape (thank you, travel points!); that’s why there’s enough room for three distinct and gorgeous dragons that fill you with excitement every time their music comes out of nowhere;\n\nthat’s why staying in the nearest stable during a thunderstorm or going deep into the arctic tundra feels so much like curling up in front of a crackling fire on a freezing cold day;\n\nthat’s why, even after completing part of a main quest, you’ll find yourself returning over and over to the same points on the map–to see an old friend, find a new side quest, or exchange some shiny rocks you could sell anywhere for a better price but you keep coming here because something about it makes you feel at home;\n\nthat’s why you can take a break in between main quests to try and ride a stag;\n\nand yes, this is an actual side quest.\nNintendo knocked this one clear out of the park. It’s so wonderfully and incredibly immersive: I go from exploring the freezing cold peaks of the Hebra mountains to chasing down a monster aficionado with a nighttime shop along the southeastern coastline with absolutely no recollection of how I transitioned from one to the other.\nBut by far, the single biggest surprise is the plot. It’s nuanced, and mysterious, and even chilling in some cases, and it has me on the edge of my seat wanting to know what happens next. Previously, I’ve always felt the plot in Zelda games was a perpetual weakness: Zelda/Link good, Ganon bad, bludgeon Ganon until bad goes away and credits roll. But this game–at least so far (I’m not done yet)–makes me think there’s something at work beyond Ganon and his usual hijinks. The “good guys” in particular don’t seem perfect; I’m being led to think they made mistakes!\nSadly, classes start this week, so it’s unlikely I’ll be making fast progress over the next few months. But I do know The Lady was pretty thrilled to unlock one particular character from previous Zelda games who, while technically present in this game, required some external convincing to join the quest:\n\nI am loving everything about this game. Go buy it and forget reality! It’s a great way to kill time while healing from an injury.\n\n\n\nCitationBibTeX citation:@online{quinn2019,\n  author = {Shannon Quinn},\n  title = {Breath of {Fresh} (Albeit, Indoor) {Air}},\n  date = {2019-08-12},\n  url = {https://magsol.github.io/2019-08-12-breath-of-the-wild},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nShannon Quinn. 2019. “Breath of Fresh (Albeit, Indoor)\nAir.” August 12, 2019. https://magsol.github.io/2019-08-12-breath-of-the-wild."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "My name is Shannon Quinn. I’m an associate professor in the School of Computer Science and Department of Cellular Biology at the University of Georgia. Which is ironic at some level, considering my undergraduate degree in Computer Science came from Georgia Tech (GO JACKETS).\nMy interests are pretty broad, but the best summary I can give is that I enjoy hacking at large-scale data science problems. Recently I’ve been getting into DevOps, and ways of operationalizing machine learning; reproducibility is very important to me, and anything that helps make the hidden work of preprocessing, pretraining, and even precoding explicit is a good idea in my book. Perhaps unsurprisingly, I’m a huge proponent of open source development, and a big believer in open science. I try to make tools, data, and course materials all available with open source licenses, and try to give back to the open source communities whenever and however I can.\nIn my copious (lulz) free time, I enjoy board gaming, video gaming, and anything that involves working up a sweat: baseball, football, basketball, racquetball, cycling, hiking, and especially running."
  }
]